{
 "cells": [
  {
   "cell_type": "code",
   "execution_count": 1,
   "id": "d14fc631",
   "metadata": {},
   "outputs": [],
   "source": [
    "import os\n",
    "import pandas as pd\n",
    "import numpy as np"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 2,
   "id": "5f43cd85",
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "['.ipynb_checkpoints',\n",
       " 'MotionSenseHAR.txt',\n",
       " 'MotionSenseHAR_TEST.ts',\n",
       " 'MotionSenseHAR_TRAIN.ts',\n",
       " 'Untitled.ipynb',\n",
       " '실습_MotionSense_DataPreprocessing.ipynb',\n",
       " '실습_MotionSense_Modeling.ipynb']"
      ]
     },
     "execution_count": 2,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "os.listdir()"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "25140d36",
   "metadata": {},
   "source": [
    "# 데이터 전처리\n",
    "Sample1 X1 [t1, t2, t3....] : X2 [t1, t2, t3....] ....<br>\n",
    "Sample2 X1 [t1, t2, t3....] : X2 [t1, t2, t3....] .... <br>\n",
    "\n",
    "이런 데이터를 (Sample, Time, Feature)의 numpy array로 만들기"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 3,
   "id": "04a21760",
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "(965, 1000, 12)"
      ]
     },
     "execution_count": 3,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "Train = pd.read_csv(\"MotionSenseHAR_TRAIN.ts\", skiprows=10, sep=\":\")\n",
    "\n",
    "Train_y = Train.iloc[:, 12]\n",
    "Train_y = pd.get_dummies(Train_y)\n",
    "\n",
    "Train_x = []\n",
    "for RowIndex in range(Train.shape[0]):\n",
    "    Features = []\n",
    "    for ColIndex in range(0, 12):\n",
    "        Features.append([float(Digit) for Digit in Train.iloc[RowIndex, ColIndex].split(\", \")])\n",
    "    Train_x.append(np.stack(Features).transpose())\n",
    "Train_x = np.stack(Train_x)\n",
    "Train_x.shape"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 4,
   "id": "205eca0e",
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "(264, 1000, 12)"
      ]
     },
     "execution_count": 4,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "Test = pd.read_csv(\"MotionSenseHAR_Test.ts\", skiprows=10, sep=\":\")\n",
    "\n",
    "Test_y = Test.iloc[:, 12]\n",
    "Test_y = pd.get_dummies(Test_y)\n",
    "\n",
    "Test_x = []\n",
    "for RowIndex in range(Test.shape[0]):\n",
    "    Features = []\n",
    "    for ColIndex in range(0, 12):\n",
    "        Features.append([float(Digit) for Digit in Test.iloc[RowIndex, ColIndex].split(\", \")])\n",
    "    Test_x.append(np.stack(Features).transpose())\n",
    "Test_x = np.stack(Test_x)\n",
    "Test_x.shape"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "12a5c794",
   "metadata": {},
   "source": [
    "### Data Shuffle"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 5,
   "id": "25003aac",
   "metadata": {},
   "outputs": [],
   "source": [
    "arr = np.arange(Train_x.shape[0])\n",
    "np.random.shuffle(arr)\n",
    "\n",
    "Train_x = Train_x[arr]\n",
    "Train_y = Train_y.iloc[arr]"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 6,
   "id": "627ca760",
   "metadata": {},
   "outputs": [],
   "source": [
    "arr = np.arange(Test_x.shape[0])\n",
    "np.random.shuffle(arr)\n",
    "\n",
    "Test_x = Test_x[arr]\n",
    "Test_y = Test_y.iloc[arr]"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "844575d7",
   "metadata": {},
   "source": [
    "### 1D convoltuion 딥러닝으로 Time series 데이터 분석"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 7,
   "id": "7f2f1bcf",
   "metadata": {},
   "outputs": [],
   "source": [
    "import tensorflow as tf\n",
    "from tensorflow.keras.models import Sequential, load_model\n",
    "from tensorflow.keras.layers import Dense, SimpleRNN, TimeDistributed, LSTM, GRU, Bidirectional\n",
    "from tensorflow.keras.optimizers import SGD, Adam\n",
    "from tensorflow.keras.callbacks import ModelCheckpoint, TensorBoard, ReduceLROnPlateau"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 8,
   "id": "fe08ca41",
   "metadata": {},
   "outputs": [],
   "source": [
    "TimeDomain = 1000\n",
    "nFeatures = 12\n",
    "n_feature_maps = 64"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 10,
   "id": "c3d70424",
   "metadata": {},
   "outputs": [],
   "source": [
    "input_layer = tf.keras.layers.Input( (TimeDomain, nFeatures, ) )\n",
    "conv_x = tf.keras.layers.Conv1D(filters=n_feature_maps, kernel_size=8, padding='same')(input_layer)\n",
    "conv_x = tf.keras.layers.BatchNormalization()(conv_x)\n",
    "conv_x = tf.keras.layers.Activation('relu')(conv_x)\n",
    "conv_x = tf.keras.layers.Dropout(rate=0.1)(conv_x)\n",
    "\n",
    "conv_y = tf.keras.layers.Conv1D(filters=n_feature_maps, kernel_size=5, padding='same')(conv_x)\n",
    "conv_y = tf.keras.layers.BatchNormalization()(conv_y)\n",
    "conv_y = tf.keras.layers.Activation('relu')(conv_y)\n",
    "conv_x = tf.keras.layers.Dropout(rate=0.1)(conv_x)\n",
    "\n",
    "conv_z = tf.keras.layers.Conv1D(filters=n_feature_maps, kernel_size=3, padding='same')(conv_y)\n",
    "conv_z = tf.keras.layers.BatchNormalization()(conv_z)\n",
    "\n",
    "\n",
    "# expand channels for the sum\n",
    "shortcut_y = tf.keras.layers.Conv1D(filters=n_feature_maps, kernel_size=1, padding='same')(input_layer)\n",
    "shortcut_y = tf.keras.layers.BatchNormalization()(shortcut_y)\n",
    "\n",
    "output_block_1 = tf.keras.layers.add([shortcut_y, conv_z])\n",
    "output_block_1 = tf.keras.layers.Activation('relu')(output_block_1)\n",
    "conv_x = tf.keras.layers.Dropout(rate=0.1)(conv_x)\n",
    "\n",
    "# BLOCK 2\n",
    "\n",
    "conv_x = tf.keras.layers.Conv1D(filters=n_feature_maps * 2, kernel_size=8, padding='same')(output_block_1)\n",
    "conv_x = tf.keras.layers.BatchNormalization()(conv_x)\n",
    "conv_x = tf.keras.layers.Activation('relu')(conv_x)\n",
    "conv_x = tf.keras.layers.Dropout(rate=0.1)(conv_x)\n",
    "\n",
    "conv_y = tf.keras.layers.Conv1D(filters=n_feature_maps * 2, kernel_size=5, padding='same')(conv_x)\n",
    "conv_y = tf.keras.layers.BatchNormalization()(conv_y)\n",
    "conv_y = tf.keras.layers.Activation('relu')(conv_y)\n",
    "conv_x = tf.keras.layers.Dropout(rate=0.1)(conv_x)\n",
    "\n",
    "conv_z = tf.keras.layers.Conv1D(filters=n_feature_maps * 2, kernel_size=3, padding='same')(conv_y)\n",
    "conv_z = tf.keras.layers.BatchNormalization()(conv_z)\n",
    "\n",
    "\n",
    "# expand channels for the sum\n",
    "shortcut_y = tf.keras.layers.Conv1D(filters=n_feature_maps * 2, kernel_size=1, padding='same')(output_block_1)\n",
    "shortcut_y = tf.keras.layers.BatchNormalization()(shortcut_y)\n",
    "\n",
    "output_block_2 = tf.keras.layers.add([shortcut_y, conv_z])\n",
    "output_block_2 = tf.keras.layers.Activation('relu')(output_block_2)\n",
    "conv_x = tf.keras.layers.Dropout(rate=0.1)(conv_x)\n",
    "\n",
    "# BLOCK 3\n",
    "\n",
    "conv_x = tf.keras.layers.Conv1D(filters=n_feature_maps * 2, kernel_size=8, padding='same')(output_block_2)\n",
    "conv_x = tf.keras.layers.BatchNormalization()(conv_x)\n",
    "conv_x = tf.keras.layers.Activation('relu')(conv_x)\n",
    "conv_x = tf.keras.layers.Dropout(rate=0.1)(conv_x)\n",
    "\n",
    "conv_y = tf.keras.layers.Conv1D(filters=n_feature_maps * 2, kernel_size=5, padding='same')(conv_x)\n",
    "conv_y = tf.keras.layers.BatchNormalization()(conv_y)\n",
    "conv_y = tf.keras.layers.Activation('relu')(conv_y)\n",
    "conv_x = tf.keras.layers.Dropout(rate=0.1)(conv_x)\n",
    "\n",
    "conv_z = tf.keras.layers.Conv1D(filters=n_feature_maps * 2, kernel_size=3, padding='same')(conv_y)\n",
    "conv_z = tf.keras.layers.BatchNormalization()(conv_z)\n",
    "\n",
    "# no need to expand channels because they are equal\n",
    "shortcut_y = tf.keras.layers.BatchNormalization()(output_block_2)\n",
    "\n",
    "output_block_3 = tf.keras.layers.add([shortcut_y, conv_z])\n",
    "output_block_3 = tf.keras.layers.Activation('relu')(output_block_3)\n",
    "\n",
    "# FINAL\n",
    "\n",
    "gap_layer = tf.keras.layers.GlobalAveragePooling1D()(output_block_3)\n",
    "output_layer = tf.keras.layers.Dense(6, activation='softmax')(gap_layer)\n",
    "\n",
    "model = tf.keras.models.Model(inputs=input_layer, outputs=output_layer)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 11,
   "id": "39b04ecd",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Model: \"model_1\"\n",
      "__________________________________________________________________________________________________\n",
      " Layer (type)                   Output Shape         Param #     Connected to                     \n",
      "==================================================================================================\n",
      " input_2 (InputLayer)           [(None, 1000, 12)]   0           []                               \n",
      "                                                                                                  \n",
      " conv1d_11 (Conv1D)             (None, 1000, 64)     6208        ['input_2[0][0]']                \n",
      "                                                                                                  \n",
      " batch_normalization_12 (BatchN  (None, 1000, 64)    256         ['conv1d_11[0][0]']              \n",
      " ormalization)                                                                                    \n",
      "                                                                                                  \n",
      " activation_9 (Activation)      (None, 1000, 64)     0           ['batch_normalization_12[0][0]'] \n",
      "                                                                                                  \n",
      " dropout_8 (Dropout)            (None, 1000, 64)     0           ['activation_9[0][0]']           \n",
      "                                                                                                  \n",
      " conv1d_12 (Conv1D)             (None, 1000, 64)     20544       ['dropout_8[0][0]']              \n",
      "                                                                                                  \n",
      " batch_normalization_13 (BatchN  (None, 1000, 64)    256         ['conv1d_12[0][0]']              \n",
      " ormalization)                                                                                    \n",
      "                                                                                                  \n",
      " activation_10 (Activation)     (None, 1000, 64)     0           ['batch_normalization_13[0][0]'] \n",
      "                                                                                                  \n",
      " conv1d_14 (Conv1D)             (None, 1000, 64)     832         ['input_2[0][0]']                \n",
      "                                                                                                  \n",
      " conv1d_13 (Conv1D)             (None, 1000, 64)     12352       ['activation_10[0][0]']          \n",
      "                                                                                                  \n",
      " batch_normalization_15 (BatchN  (None, 1000, 64)    256         ['conv1d_14[0][0]']              \n",
      " ormalization)                                                                                    \n",
      "                                                                                                  \n",
      " batch_normalization_14 (BatchN  (None, 1000, 64)    256         ['conv1d_13[0][0]']              \n",
      " ormalization)                                                                                    \n",
      "                                                                                                  \n",
      " add_3 (Add)                    (None, 1000, 64)     0           ['batch_normalization_15[0][0]', \n",
      "                                                                  'batch_normalization_14[0][0]'] \n",
      "                                                                                                  \n",
      " activation_11 (Activation)     (None, 1000, 64)     0           ['add_3[0][0]']                  \n",
      "                                                                                                  \n",
      " conv1d_15 (Conv1D)             (None, 1000, 128)    65664       ['activation_11[0][0]']          \n",
      "                                                                                                  \n",
      " batch_normalization_16 (BatchN  (None, 1000, 128)   512         ['conv1d_15[0][0]']              \n",
      " ormalization)                                                                                    \n",
      "                                                                                                  \n",
      " activation_12 (Activation)     (None, 1000, 128)    0           ['batch_normalization_16[0][0]'] \n",
      "                                                                                                  \n",
      " dropout_11 (Dropout)           (None, 1000, 128)    0           ['activation_12[0][0]']          \n",
      "                                                                                                  \n",
      " conv1d_16 (Conv1D)             (None, 1000, 128)    82048       ['dropout_11[0][0]']             \n",
      "                                                                                                  \n",
      " batch_normalization_17 (BatchN  (None, 1000, 128)   512         ['conv1d_16[0][0]']              \n",
      " ormalization)                                                                                    \n",
      "                                                                                                  \n",
      " activation_13 (Activation)     (None, 1000, 128)    0           ['batch_normalization_17[0][0]'] \n",
      "                                                                                                  \n",
      " conv1d_18 (Conv1D)             (None, 1000, 128)    8320        ['activation_11[0][0]']          \n",
      "                                                                                                  \n",
      " conv1d_17 (Conv1D)             (None, 1000, 128)    49280       ['activation_13[0][0]']          \n",
      "                                                                                                  \n",
      " batch_normalization_19 (BatchN  (None, 1000, 128)   512         ['conv1d_18[0][0]']              \n",
      " ormalization)                                                                                    \n",
      "                                                                                                  \n",
      " batch_normalization_18 (BatchN  (None, 1000, 128)   512         ['conv1d_17[0][0]']              \n",
      " ormalization)                                                                                    \n",
      "                                                                                                  \n",
      " add_4 (Add)                    (None, 1000, 128)    0           ['batch_normalization_19[0][0]', \n",
      "                                                                  'batch_normalization_18[0][0]'] \n",
      "                                                                                                  \n",
      " activation_14 (Activation)     (None, 1000, 128)    0           ['add_4[0][0]']                  \n",
      "                                                                                                  \n",
      " conv1d_19 (Conv1D)             (None, 1000, 128)    131200      ['activation_14[0][0]']          \n",
      "                                                                                                  \n",
      " batch_normalization_20 (BatchN  (None, 1000, 128)   512         ['conv1d_19[0][0]']              \n",
      " ormalization)                                                                                    \n",
      "                                                                                                  \n",
      " activation_15 (Activation)     (None, 1000, 128)    0           ['batch_normalization_20[0][0]'] \n",
      "                                                                                                  \n",
      " dropout_14 (Dropout)           (None, 1000, 128)    0           ['activation_15[0][0]']          \n",
      "                                                                                                  \n",
      " conv1d_20 (Conv1D)             (None, 1000, 128)    82048       ['dropout_14[0][0]']             \n",
      "                                                                                                  \n",
      " batch_normalization_21 (BatchN  (None, 1000, 128)   512         ['conv1d_20[0][0]']              \n",
      " ormalization)                                                                                    \n",
      "                                                                                                  \n",
      " activation_16 (Activation)     (None, 1000, 128)    0           ['batch_normalization_21[0][0]'] \n",
      "                                                                                                  \n",
      " conv1d_21 (Conv1D)             (None, 1000, 128)    49280       ['activation_16[0][0]']          \n",
      "                                                                                                  \n",
      " batch_normalization_23 (BatchN  (None, 1000, 128)   512         ['activation_14[0][0]']          \n",
      " ormalization)                                                                                    \n",
      "                                                                                                  \n",
      " batch_normalization_22 (BatchN  (None, 1000, 128)   512         ['conv1d_21[0][0]']              \n",
      " ormalization)                                                                                    \n",
      "                                                                                                  \n",
      " add_5 (Add)                    (None, 1000, 128)    0           ['batch_normalization_23[0][0]', \n",
      "                                                                  'batch_normalization_22[0][0]'] \n",
      "                                                                                                  \n",
      " activation_17 (Activation)     (None, 1000, 128)    0           ['add_5[0][0]']                  \n",
      "                                                                                                  \n",
      " global_average_pooling1d_1 (Gl  (None, 128)         0           ['activation_17[0][0]']          \n",
      " obalAveragePooling1D)                                                                            \n",
      "                                                                                                  \n",
      " dense_1 (Dense)                (None, 6)            774         ['global_average_pooling1d_1[0][0\n",
      "                                                                 ]']                              \n",
      "                                                                                                  \n",
      "==================================================================================================\n",
      "Total params: 513,670\n",
      "Trainable params: 511,110\n",
      "Non-trainable params: 2,560\n",
      "__________________________________________________________________________________________________\n"
     ]
    }
   ],
   "source": [
    "model.compile(loss = \"categorical_crossentropy\", optimizer=Adam(learning_rate=0.001), metrics=['accuracy'])\n",
    "model.summary()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 65,
   "id": "e039e92b",
   "metadata": {},
   "outputs": [],
   "source": [
    "FinalModel.compile(loss = \"categorical_crossentropy\", optimizer=Adam(learning_rate=0.005), metrics=['accuracy'])"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "35c238ea",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Epoch 1/100\n",
      "121/121 [==============================] - 28s 210ms/step - loss: 0.5850 - accuracy: 0.7948 - val_loss: 1.0962 - val_accuracy: 0.7008\n",
      "Epoch 2/100\n",
      "121/121 [==============================] - 26s 216ms/step - loss: 0.3098 - accuracy: 0.9088 - val_loss: 1.5423 - val_accuracy: 0.7500\n",
      "Epoch 3/100\n",
      "  6/121 [>.............................] - ETA: 22s - loss: 0.1904 - accuracy: 0.9792"
     ]
    }
   ],
   "source": [
    "history_finetunning = model.fit(\n",
    "    Train_x, Train_y,\n",
    "    epochs=100,\n",
    "    batch_size=8,\n",
    "    #callbacks=CALLBACK,\n",
    "    validation_data=(Test_x, Test_y),\n",
    "    shuffle=True)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "ffb8f55f",
   "metadata": {},
   "outputs": [],
   "source": []
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "Python 3 (ipykernel)",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.9.7"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 5
}
