{
 "cells": [
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "코드 출처: https://github.com/deepseasw/seq2seq_chatbot<br>"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 1,
   "metadata": {},
   "outputs": [],
   "source": [
    "from tensorflow import keras\n",
    "from tensorflow.keras import models\n",
    "from tensorflow.keras import layers\n",
    "from tensorflow.keras import optimizers, losses, metrics\n",
    "from tensorflow.keras import preprocessing\n",
    "\n",
    "import numpy as np\n",
    "import pandas as pd\n",
    "import matplotlib.pyplot as plt\n",
    "import pickle\n",
    "import os\n",
    "import re\n",
    "\n",
    "from konlpy.tag import Okt"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "<br>\n",
    "<br>\n",
    "\n",
    "# 데이터 로드"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "Seq2Seq에서의 임베딩이 이전 예제와 다른 점은 아래와 같이 태그를 사용한다는 것입니다.<br>\n",
    "임베딩의 0~3번째에 각각 PADDING, START, END, OOV 태그를 넣습니다.<br>\n",
    "사실 그냥 똑같은 단어라고 보시면 됩니다. 다만 이 단어들이 Seq2Seq의 동작을 제어합니다. <br>\n",
    "<br>\n",
    "예를 들어, 디코더 입력에 START가 들어가면 디코딩의 시작을 의미합니다. 반대로 디코더 출력에 END가 나오면 디코딩을 종료합니다.<br>"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 2,
   "metadata": {},
   "outputs": [],
   "source": [
    "# 태그 단어\n",
    "PAD = \"<PADDING>\"   # 패딩\n",
    "STA = \"<START>\"     # 시작\n",
    "END = \"<END>\"       # 끝\n",
    "OOV = \"<OOV>\"       # 없는 단어(Out of Vocabulary)\n",
    "\n",
    "# 태그 인덱스\n",
    "PAD_INDEX = 0\n",
    "STA_INDEX = 1\n",
    "END_INDEX = 2\n",
    "OOV_INDEX = 3\n",
    "\n",
    "# 데이터 타입\n",
    "ENCODER_INPUT  = 0\n",
    "DECODER_INPUT  = 1\n",
    "DECODER_TARGET = 2\n",
    "\n",
    "# 한 문장에서 단어 시퀀스의 최대 개수\n",
    "max_sequences = 30\n",
    "\n",
    "# 임베딩 벡터 차원\n",
    "embedding_dim = 100\n",
    "\n",
    "# LSTM 히든레이어 차원\n",
    "lstm_hidden_dim = 128\n",
    "\n",
    "# 정규 표현식 필터\n",
    "RE_FILTER = re.compile(\"[.,!?\\\"':;~()]\")\n",
    "\n",
    "# 챗봇 데이터 로드\n",
    "chatbot_data = pd.read_csv('./dataset/chatbot/ChatbotData.csv', encoding='utf-8')\n",
    "question, answer = list(chatbot_data['Q']), list(chatbot_data['A'])"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "챗봇의 훈련을 위해서 송영숙님이 공개한 한글 데이터셋을 로드합니다.<br>\n",
    "질문과 대답, 감정 등 총 3개의 항목으로 구성되어 있습니다.<br>\n",
    "감정 분류는 Seq2Seq에 필요가 없기 때문에 사용하지 않습니다.<br>\n",
    "https://github.com/songys/Chatbot_data<br>\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 3,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "11824"
      ]
     },
     "execution_count": 3,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "# 데이터 개수\n",
    "len(question)\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 4,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Q : 12시 땡!\n",
      "A : 하루가 또 가네요.\n",
      "\n",
      "Q : 1지망 학교 떨어졌어\n",
      "A : 위로해 드립니다.\n",
      "\n",
      "Q : 3박4일 놀러가고 싶다\n",
      "A : 여행은 언제나 좋죠.\n",
      "\n",
      "Q : 3박4일 정도 놀러가고 싶다\n",
      "A : 여행은 언제나 좋죠.\n",
      "\n",
      "Q : PPL 심하네\n",
      "A : 눈살이 찌푸려지죠.\n",
      "\n",
      "Q : SD카드 망가졌어\n",
      "A : 다시 새로 사는 게 마음 편해요.\n",
      "\n",
      "Q : SD카드 안돼\n",
      "A : 다시 새로 사는 게 마음 편해요.\n",
      "\n",
      "Q : SNS 맞팔 왜 안하지ㅠㅠ\n",
      "A : 잘 모르고 있을 수도 있어요.\n",
      "\n",
      "Q : SNS 시간낭비인 거 아는데 매일 하는 중\n",
      "A : 시간을 정하고 해보세요.\n",
      "\n",
      "Q : SNS 시간낭비인데 자꾸 보게됨\n",
      "A : 시간을 정하고 해보세요.\n",
      "\n"
     ]
    }
   ],
   "source": [
    "# 데이터의 일부만 학습에 사용\n",
    "question = question[:100]\n",
    "answer = answer[:100]\n",
    "\n",
    "# 챗봇 데이터 출력\n",
    "for i in range(10):\n",
    "    print('Q : ' + question[i])\n",
    "    print('A : ' + answer[i])\n",
    "    print()\n"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "<br>\n",
    "<br>\n",
    "\n",
    "# 단어 사전 생성"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 5,
   "metadata": {},
   "outputs": [],
   "source": [
    "# 형태소분석 함수\n",
    "def pos_tag(sentences):\n",
    "    \n",
    "    # KoNLPy 형태소분석기 설정\n",
    "    tagger = Okt()\n",
    "    \n",
    "    # 문장 품사 변수 초기화\n",
    "    sentences_pos = []\n",
    "    \n",
    "    # 모든 문장 반복\n",
    "    for sentence in sentences:\n",
    "        # 특수기호 제거\n",
    "        # RE_FILTER에 해당되는 정규표현식 char에 대하여 \"\" ()로 바꾸어라\n",
    "        sentence = re.sub(RE_FILTER, \"\", sentence)\n",
    "        \n",
    "        # 배열인 형태소분석의 출력을 띄어쓰기로 구분하여 붙임\n",
    "        sentence = \" \".join(tagger.morphs(sentence))\n",
    "        sentences_pos.append(sentence)\n",
    "        \n",
    "    return sentences_pos"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 6,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Q : 12시 땡\n",
      "A : 하루 가 또 가네요\n",
      "\n",
      "Q : 1 지망 학교 떨어졌어\n",
      "A : 위로 해 드립니다\n",
      "\n",
      "Q : 3 박 4일 놀러 가고 싶다\n",
      "A : 여행 은 언제나 좋죠\n",
      "\n",
      "Q : 3 박 4일 정도 놀러 가고 싶다\n",
      "A : 여행 은 언제나 좋죠\n",
      "\n",
      "Q : PPL 심하네\n",
      "A : 눈살 이 찌푸려지죠\n",
      "\n",
      "Q : SD 카드 망가졌어\n",
      "A : 다시 새로 사는 게 마음 편해요\n",
      "\n",
      "Q : SD 카드 안 돼\n",
      "A : 다시 새로 사는 게 마음 편해요\n",
      "\n",
      "Q : SNS 맞팔 왜 안 하지 ㅠㅠ\n",
      "A : 잘 모르고 있을 수도 있어요\n",
      "\n",
      "Q : SNS 시간 낭비 인 거 아는데 매일 하는 중\n",
      "A : 시간 을 정 하고 해보세요\n",
      "\n",
      "Q : SNS 시간 낭비 인데 자꾸 보게 됨\n",
      "A : 시간 을 정 하고 해보세요\n",
      "\n"
     ]
    }
   ],
   "source": [
    "# 형태소분석 수행\n",
    "question = pos_tag(question)\n",
    "answer = pos_tag(answer)\n",
    "\n",
    "# 형태소분석으로 변환된 챗봇 데이터 출력\n",
    "for i in range(10):\n",
    "    print('Q : ' + question[i])\n",
    "    print('A : ' + answer[i])\n",
    "    print()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 7,
   "metadata": {},
   "outputs": [],
   "source": [
    "# 질문과 대답 문장들을 하나로 합침\n",
    "sentences = []\n",
    "sentences.extend(question)\n",
    "sentences.extend(answer)\n",
    "\n",
    "words = []\n",
    "\n",
    "# 단어들의 배열 생성\n",
    "for sentence in sentences:\n",
    "    for word in sentence.split():\n",
    "        words.append(word)\n",
    "\n",
    "# 길이가 0인 단어는 삭제\n",
    "words = [word for word in words if len(word) > 0]\n",
    "\n",
    "# 중복된 단어 삭제\n",
    "words = list(set(words))\n",
    "\n",
    "# 제일 앞에 태그 단어 삽입\n",
    "words[:0] = [PAD, STA, END, OOV]"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "질문과 대답 문장들을 합쳐서 전체 단어 사전을 만듭니다.<br>\n",
    "자연어처리에서는 항상 이렇게 단어를 인덱스에 따라 정리를 해야 합니다.<br>\n",
    "<br>\n",
    "그래야지 문장을 인덱스 배열로 바꿔서 임베딩 레이어에 넣을 수 있습니다.<br>\n",
    "또한 모델의 출력에서 나온 인덱스를 다시 단어로 변환하는데도 필요합니다.<br>\n",
    "<br>"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 8,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "454"
      ]
     },
     "execution_count": 8,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "# 단어 개수\n",
    "len(words)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 9,
   "metadata": {
    "scrolled": true,
    "tags": []
   },
   "outputs": [
    {
     "data": {
      "text/plain": [
       "['<PADDING>',\n",
       " '<START>',\n",
       " '<END>',\n",
       " '<OOV>',\n",
       " '쇼핑',\n",
       " '서로',\n",
       " '달',\n",
       " '건데',\n",
       " '이나',\n",
       " '되',\n",
       " '변화',\n",
       " '즐거운',\n",
       " '생각',\n",
       " '콕',\n",
       " '벗어나는',\n",
       " '마세요',\n",
       " '있어요',\n",
       " '하',\n",
       " '누굴',\n",
       " '가지',\n",
       " '사세요',\n",
       " '일',\n",
       " '지망',\n",
       " '매일',\n",
       " '갈거야',\n",
       " '인게',\n",
       " '심하네',\n",
       " '다음',\n",
       " '엉망',\n",
       " '무시',\n",
       " '됐으면',\n",
       " '했어',\n",
       " '괜찮아요',\n",
       " '후회',\n",
       " '풀었어',\n",
       " '아님',\n",
       " '남겨야',\n",
       " '해보세요',\n",
       " '있어',\n",
       " '힘든데',\n",
       " '있을까',\n",
       " '식혀주세요',\n",
       " '좋아요',\n",
       " '옴',\n",
       " '간다',\n",
       " '걸린',\n",
       " '듣고',\n",
       " '그럴',\n",
       " '1',\n",
       " '없어',\n",
       " '먹었는데',\n",
       " '드립니다',\n",
       " '보내고',\n",
       " '절약',\n",
       " '간장',\n",
       " '말',\n",
       " '개념',\n",
       " '처럼',\n",
       " '사이',\n",
       " '키워',\n",
       " '말랭이',\n",
       " '같아',\n",
       " '마음',\n",
       " '좋은',\n",
       " '그건',\n",
       " '감미로운',\n",
       " '감기',\n",
       " '떨리니까',\n",
       " '역시',\n",
       " '편해요',\n",
       " '알려',\n",
       " '알',\n",
       " '첫인상',\n",
       " '그',\n",
       " '싶은데',\n",
       " '시켜',\n",
       " '좋다',\n",
       " '자의',\n",
       " '개강',\n",
       " '누구',\n",
       " '일도',\n",
       " '해봐요',\n",
       " '야',\n",
       " '좋겠다',\n",
       " '낮잠',\n",
       " '진창',\n",
       " '입어볼까',\n",
       " '기름',\n",
       " '부터는',\n",
       " '돼겠지',\n",
       " '쉬는',\n",
       " '추천',\n",
       " '갑자기',\n",
       " '살쪄도',\n",
       " '출발',\n",
       " '될',\n",
       " '좋죠',\n",
       " '나쁜',\n",
       " '사는',\n",
       " '왜',\n",
       " '연인',\n",
       " '이에요',\n",
       " '상황',\n",
       " '나갔어',\n",
       " '말까',\n",
       " '물어',\n",
       " '가네요',\n",
       " '가스',\n",
       " '어필',\n",
       " '데이터',\n",
       " '불',\n",
       " '책임질',\n",
       " '하루',\n",
       " '있어도',\n",
       " '당황',\n",
       " '뭘',\n",
       " '중',\n",
       " '니까',\n",
       " 'PPL',\n",
       " '보고싶었나',\n",
       " '하는',\n",
       " '까',\n",
       " '기관',\n",
       " '불편한',\n",
       " '하겠어',\n",
       " '하는데',\n",
       " '만',\n",
       " '을',\n",
       " '아름다운',\n",
       " 'ㅠㅠ',\n",
       " '3초',\n",
       " '됨',\n",
       " '켜놓고',\n",
       " '세수',\n",
       " '싫어',\n",
       " '고민',\n",
       " '생활',\n",
       " '좋아',\n",
       " '곳',\n",
       " '어디',\n",
       " '가끔',\n",
       " '무모한',\n",
       " '좋아해주세요',\n",
       " '로',\n",
       " '가세',\n",
       " '가려고',\n",
       " '공적',\n",
       " '자체',\n",
       " '짧죠',\n",
       " '갈',\n",
       " '의',\n",
       " '물어보세요',\n",
       " '병원',\n",
       " '놀러',\n",
       " '땡',\n",
       " '뭐',\n",
       " '에',\n",
       " '집',\n",
       " '참',\n",
       " '보고',\n",
       " '나온거',\n",
       " '부모님',\n",
       " '모르고',\n",
       " '비싼데',\n",
       " '가고',\n",
       " '있을',\n",
       " '맛있게',\n",
       " '오세요',\n",
       " '궁금해',\n",
       " '때',\n",
       " '낭비하지',\n",
       " '연락',\n",
       " '좋더라',\n",
       " '이럴',\n",
       " '까지',\n",
       " '싶네요',\n",
       " '꼈어',\n",
       " '이야기',\n",
       " '같아요',\n",
       " '걔',\n",
       " '않을',\n",
       " '걸리겠어',\n",
       " '못',\n",
       " '보면',\n",
       " '눈물',\n",
       " '먹고',\n",
       " '고고',\n",
       " '놓고',\n",
       " '컨트롤',\n",
       " '시켜야지',\n",
       " '기회',\n",
       " '떨리는',\n",
       " '키울까',\n",
       " '하세요',\n",
       " '할',\n",
       " '봐요',\n",
       " '또',\n",
       " '가장',\n",
       " '간접흡연',\n",
       " '찌푸려지죠',\n",
       " '좋겠네요',\n",
       " '눈살',\n",
       " '들더라',\n",
       " '최고',\n",
       " '먹어야지',\n",
       " '그게',\n",
       " '해보여',\n",
       " '개학',\n",
       " '끌',\n",
       " '매력',\n",
       " '새',\n",
       " '저',\n",
       " '학교',\n",
       " '된',\n",
       " '가만',\n",
       " '싶다',\n",
       " '같',\n",
       " '언제나',\n",
       " '쫄딱',\n",
       " '개',\n",
       " '사는게',\n",
       " '행복',\n",
       " '빨리',\n",
       " '예쁘게',\n",
       " '강아지',\n",
       " '드세요',\n",
       " '끄고',\n",
       " '소중해요',\n",
       " '인',\n",
       " '해도',\n",
       " '단',\n",
       " '제일',\n",
       " '너무',\n",
       " '집어서',\n",
       " '서먹해',\n",
       " '키우고',\n",
       " '싫어요',\n",
       " '그런거니',\n",
       " '즐기세요',\n",
       " '가보세요',\n",
       " '결정',\n",
       " '강원도',\n",
       " '오려나',\n",
       " '12시',\n",
       " '가기',\n",
       " '애',\n",
       " '봐서',\n",
       " '되겠네요',\n",
       " '관리',\n",
       " '버렸어',\n",
       " '알아차려도',\n",
       " 'SNS',\n",
       " '할까',\n",
       " '피',\n",
       " '살찐',\n",
       " '바빠서',\n",
       " '보게',\n",
       " '간만',\n",
       " '되나',\n",
       " '만나지',\n",
       " '빼고',\n",
       " '같은',\n",
       " '키울',\n",
       " '옷',\n",
       " '나오세요',\n",
       " '처음',\n",
       " '싫다',\n",
       " '안',\n",
       " '내일',\n",
       " '강의',\n",
       " '끼리',\n",
       " '먹을까',\n",
       " '해볼까',\n",
       " '도',\n",
       " '아는데',\n",
       " '갈까',\n",
       " '가자고',\n",
       " '나왔다',\n",
       " '혼자',\n",
       " '가난한',\n",
       " '게임',\n",
       " '친구',\n",
       " '사람',\n",
       " '부터',\n",
       " '드는',\n",
       " '만들어',\n",
       " '이다',\n",
       " '했잖아',\n",
       " '따뜻하게',\n",
       " '왔나',\n",
       " '수',\n",
       " '있으면',\n",
       " '내',\n",
       " '가서',\n",
       " '하자고',\n",
       " '다시',\n",
       " '곧',\n",
       " '진리',\n",
       " '보세요',\n",
       " '많이',\n",
       " '망함',\n",
       " '봅니다',\n",
       " '잊고',\n",
       " '여행',\n",
       " '가야',\n",
       " '수영장',\n",
       " '같이',\n",
       " '붙잡고',\n",
       " '정',\n",
       " '아픈가요',\n",
       " '짠으로',\n",
       " '업무',\n",
       " '들어올',\n",
       " '물어봐서',\n",
       " '자꾸',\n",
       " '장난',\n",
       " '시간',\n",
       " '개인',\n",
       " '잘',\n",
       " '해주세요',\n",
       " '싶어',\n",
       " '하고',\n",
       " '하는지',\n",
       " '들',\n",
       " '새로',\n",
       " '자도',\n",
       " '감',\n",
       " '이라니',\n",
       " '룩',\n",
       " '취미',\n",
       " '다',\n",
       " '쓰레기통',\n",
       " '4일',\n",
       " '잠깐',\n",
       " '강렬한',\n",
       " '해',\n",
       " '모두',\n",
       " '으로',\n",
       " '갑작스러웠나',\n",
       " '망가졌어',\n",
       " '에는',\n",
       " '나를',\n",
       " '부족했나',\n",
       " '관계',\n",
       " '필요하죠',\n",
       " '하면',\n",
       " '했길',\n",
       " '준',\n",
       " '화폐',\n",
       " '것',\n",
       " '적',\n",
       " '질질',\n",
       " '켜고',\n",
       " '줘',\n",
       " '요',\n",
       " '에요',\n",
       " '패턴',\n",
       " '난다',\n",
       " '예요',\n",
       " '데',\n",
       " '막',\n",
       " '목소리',\n",
       " '어제',\n",
       " '당신',\n",
       " '두',\n",
       " '인거',\n",
       " '온',\n",
       " '리지',\n",
       " '개시',\n",
       " '스트레스',\n",
       " '가출',\n",
       " '주는',\n",
       " '하느라',\n",
       " '자리',\n",
       " '치킨',\n",
       " '를',\n",
       " '이야',\n",
       " '운',\n",
       " '건',\n",
       " '지',\n",
       " '입어',\n",
       " '랑',\n",
       " '돈',\n",
       " '씨방',\n",
       " '약',\n",
       " '가족',\n",
       " '애가',\n",
       " '사랑',\n",
       " '정말',\n",
       " '거',\n",
       " '한테',\n",
       " '간식',\n",
       " '인데',\n",
       " '3',\n",
       " '떨어졌어',\n",
       " '수도',\n",
       " '돼',\n",
       " '위로',\n",
       " '맞팔',\n",
       " '박',\n",
       " '볼까',\n",
       " '더',\n",
       " '싫어하지',\n",
       " '서먹해졌어',\n",
       " '정도',\n",
       " '기운',\n",
       " '오늘이',\n",
       " '감히',\n",
       " '게',\n",
       " '죠',\n",
       " '설움',\n",
       " '알아차리지',\n",
       " '이',\n",
       " '닮아서',\n",
       " '중요해요',\n",
       " '확실한',\n",
       " '함께',\n",
       " '휴식',\n",
       " '바라요',\n",
       " '와',\n",
       " '은',\n",
       " '자신',\n",
       " 'SD',\n",
       " '믿어',\n",
       " '가까워질',\n",
       " '어서',\n",
       " '있는',\n",
       " '비',\n",
       " '낭비',\n",
       " '살까',\n",
       " '중요한',\n",
       " '졸려',\n",
       " '득템',\n",
       " '살펴',\n",
       " '습관',\n",
       " '아세요',\n",
       " '먼저',\n",
       " '감정',\n",
       " '선생님',\n",
       " '어떤것',\n",
       " '없죠',\n",
       " '나',\n",
       " '되도록',\n",
       " '는',\n",
       " '방학',\n",
       " '반',\n",
       " '땀',\n",
       " '가상',\n",
       " '하지',\n",
       " '자랑',\n",
       " '돌아가서',\n",
       " '이랑',\n",
       " '가',\n",
       " '카드']"
      ]
     },
     "execution_count": 9,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "# 단어 출력\n",
    "words"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 10,
   "metadata": {},
   "outputs": [],
   "source": [
    "# 단어와 인덱스의 딕셔너리 생성, Series.count_values()도 가능\n",
    "word_to_index = {word: index for index, word in enumerate(words)}\n",
    "index_to_word = {index: word for index, word in enumerate(words)}"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 11,
   "metadata": {
    "scrolled": true,
    "tags": []
   },
   "outputs": [
    {
     "data": {
      "text/plain": [
       "{'<PADDING>': 0,\n",
       " '<START>': 1,\n",
       " '<END>': 2,\n",
       " '<OOV>': 3,\n",
       " '쇼핑': 4,\n",
       " '서로': 5,\n",
       " '달': 6,\n",
       " '건데': 7,\n",
       " '이나': 8,\n",
       " '되': 9,\n",
       " '변화': 10,\n",
       " '즐거운': 11,\n",
       " '생각': 12,\n",
       " '콕': 13,\n",
       " '벗어나는': 14,\n",
       " '마세요': 15,\n",
       " '있어요': 16,\n",
       " '하': 17,\n",
       " '누굴': 18,\n",
       " '가지': 19,\n",
       " '사세요': 20,\n",
       " '일': 21,\n",
       " '지망': 22,\n",
       " '매일': 23,\n",
       " '갈거야': 24,\n",
       " '인게': 25,\n",
       " '심하네': 26,\n",
       " '다음': 27,\n",
       " '엉망': 28,\n",
       " '무시': 29,\n",
       " '됐으면': 30,\n",
       " '했어': 31,\n",
       " '괜찮아요': 32,\n",
       " '후회': 33,\n",
       " '풀었어': 34,\n",
       " '아님': 35,\n",
       " '남겨야': 36,\n",
       " '해보세요': 37,\n",
       " '있어': 38,\n",
       " '힘든데': 39,\n",
       " '있을까': 40,\n",
       " '식혀주세요': 41,\n",
       " '좋아요': 42,\n",
       " '옴': 43,\n",
       " '간다': 44,\n",
       " '걸린': 45,\n",
       " '듣고': 46,\n",
       " '그럴': 47,\n",
       " '1': 48,\n",
       " '없어': 49,\n",
       " '먹었는데': 50,\n",
       " '드립니다': 51,\n",
       " '보내고': 52,\n",
       " '절약': 53,\n",
       " '간장': 54,\n",
       " '말': 55,\n",
       " '개념': 56,\n",
       " '처럼': 57,\n",
       " '사이': 58,\n",
       " '키워': 59,\n",
       " '말랭이': 60,\n",
       " '같아': 61,\n",
       " '마음': 62,\n",
       " '좋은': 63,\n",
       " '그건': 64,\n",
       " '감미로운': 65,\n",
       " '감기': 66,\n",
       " '떨리니까': 67,\n",
       " '역시': 68,\n",
       " '편해요': 69,\n",
       " '알려': 70,\n",
       " '알': 71,\n",
       " '첫인상': 72,\n",
       " '그': 73,\n",
       " '싶은데': 74,\n",
       " '시켜': 75,\n",
       " '좋다': 76,\n",
       " '자의': 77,\n",
       " '개강': 78,\n",
       " '누구': 79,\n",
       " '일도': 80,\n",
       " '해봐요': 81,\n",
       " '야': 82,\n",
       " '좋겠다': 83,\n",
       " '낮잠': 84,\n",
       " '진창': 85,\n",
       " '입어볼까': 86,\n",
       " '기름': 87,\n",
       " '부터는': 88,\n",
       " '돼겠지': 89,\n",
       " '쉬는': 90,\n",
       " '추천': 91,\n",
       " '갑자기': 92,\n",
       " '살쪄도': 93,\n",
       " '출발': 94,\n",
       " '될': 95,\n",
       " '좋죠': 96,\n",
       " '나쁜': 97,\n",
       " '사는': 98,\n",
       " '왜': 99,\n",
       " '연인': 100,\n",
       " '이에요': 101,\n",
       " '상황': 102,\n",
       " '나갔어': 103,\n",
       " '말까': 104,\n",
       " '물어': 105,\n",
       " '가네요': 106,\n",
       " '가스': 107,\n",
       " '어필': 108,\n",
       " '데이터': 109,\n",
       " '불': 110,\n",
       " '책임질': 111,\n",
       " '하루': 112,\n",
       " '있어도': 113,\n",
       " '당황': 114,\n",
       " '뭘': 115,\n",
       " '중': 116,\n",
       " '니까': 117,\n",
       " 'PPL': 118,\n",
       " '보고싶었나': 119,\n",
       " '하는': 120,\n",
       " '까': 121,\n",
       " '기관': 122,\n",
       " '불편한': 123,\n",
       " '하겠어': 124,\n",
       " '하는데': 125,\n",
       " '만': 126,\n",
       " '을': 127,\n",
       " '아름다운': 128,\n",
       " 'ㅠㅠ': 129,\n",
       " '3초': 130,\n",
       " '됨': 131,\n",
       " '켜놓고': 132,\n",
       " '세수': 133,\n",
       " '싫어': 134,\n",
       " '고민': 135,\n",
       " '생활': 136,\n",
       " '좋아': 137,\n",
       " '곳': 138,\n",
       " '어디': 139,\n",
       " '가끔': 140,\n",
       " '무모한': 141,\n",
       " '좋아해주세요': 142,\n",
       " '로': 143,\n",
       " '가세': 144,\n",
       " '가려고': 145,\n",
       " '공적': 146,\n",
       " '자체': 147,\n",
       " '짧죠': 148,\n",
       " '갈': 149,\n",
       " '의': 150,\n",
       " '물어보세요': 151,\n",
       " '병원': 152,\n",
       " '놀러': 153,\n",
       " '땡': 154,\n",
       " '뭐': 155,\n",
       " '에': 156,\n",
       " '집': 157,\n",
       " '참': 158,\n",
       " '보고': 159,\n",
       " '나온거': 160,\n",
       " '부모님': 161,\n",
       " '모르고': 162,\n",
       " '비싼데': 163,\n",
       " '가고': 164,\n",
       " '있을': 165,\n",
       " '맛있게': 166,\n",
       " '오세요': 167,\n",
       " '궁금해': 168,\n",
       " '때': 169,\n",
       " '낭비하지': 170,\n",
       " '연락': 171,\n",
       " '좋더라': 172,\n",
       " '이럴': 173,\n",
       " '까지': 174,\n",
       " '싶네요': 175,\n",
       " '꼈어': 176,\n",
       " '이야기': 177,\n",
       " '같아요': 178,\n",
       " '걔': 179,\n",
       " '않을': 180,\n",
       " '걸리겠어': 181,\n",
       " '못': 182,\n",
       " '보면': 183,\n",
       " '눈물': 184,\n",
       " '먹고': 185,\n",
       " '고고': 186,\n",
       " '놓고': 187,\n",
       " '컨트롤': 188,\n",
       " '시켜야지': 189,\n",
       " '기회': 190,\n",
       " '떨리는': 191,\n",
       " '키울까': 192,\n",
       " '하세요': 193,\n",
       " '할': 194,\n",
       " '봐요': 195,\n",
       " '또': 196,\n",
       " '가장': 197,\n",
       " '간접흡연': 198,\n",
       " '찌푸려지죠': 199,\n",
       " '좋겠네요': 200,\n",
       " '눈살': 201,\n",
       " '들더라': 202,\n",
       " '최고': 203,\n",
       " '먹어야지': 204,\n",
       " '그게': 205,\n",
       " '해보여': 206,\n",
       " '개학': 207,\n",
       " '끌': 208,\n",
       " '매력': 209,\n",
       " '새': 210,\n",
       " '저': 211,\n",
       " '학교': 212,\n",
       " '된': 213,\n",
       " '가만': 214,\n",
       " '싶다': 215,\n",
       " '같': 216,\n",
       " '언제나': 217,\n",
       " '쫄딱': 218,\n",
       " '개': 219,\n",
       " '사는게': 220,\n",
       " '행복': 221,\n",
       " '빨리': 222,\n",
       " '예쁘게': 223,\n",
       " '강아지': 224,\n",
       " '드세요': 225,\n",
       " '끄고': 226,\n",
       " '소중해요': 227,\n",
       " '인': 228,\n",
       " '해도': 229,\n",
       " '단': 230,\n",
       " '제일': 231,\n",
       " '너무': 232,\n",
       " '집어서': 233,\n",
       " '서먹해': 234,\n",
       " '키우고': 235,\n",
       " '싫어요': 236,\n",
       " '그런거니': 237,\n",
       " '즐기세요': 238,\n",
       " '가보세요': 239,\n",
       " '결정': 240,\n",
       " '강원도': 241,\n",
       " '오려나': 242,\n",
       " '12시': 243,\n",
       " '가기': 244,\n",
       " '애': 245,\n",
       " '봐서': 246,\n",
       " '되겠네요': 247,\n",
       " '관리': 248,\n",
       " '버렸어': 249,\n",
       " '알아차려도': 250,\n",
       " 'SNS': 251,\n",
       " '할까': 252,\n",
       " '피': 253,\n",
       " '살찐': 254,\n",
       " '바빠서': 255,\n",
       " '보게': 256,\n",
       " '간만': 257,\n",
       " '되나': 258,\n",
       " '만나지': 259,\n",
       " '빼고': 260,\n",
       " '같은': 261,\n",
       " '키울': 262,\n",
       " '옷': 263,\n",
       " '나오세요': 264,\n",
       " '처음': 265,\n",
       " '싫다': 266,\n",
       " '안': 267,\n",
       " '내일': 268,\n",
       " '강의': 269,\n",
       " '끼리': 270,\n",
       " '먹을까': 271,\n",
       " '해볼까': 272,\n",
       " '도': 273,\n",
       " '아는데': 274,\n",
       " '갈까': 275,\n",
       " '가자고': 276,\n",
       " '나왔다': 277,\n",
       " '혼자': 278,\n",
       " '가난한': 279,\n",
       " '게임': 280,\n",
       " '친구': 281,\n",
       " '사람': 282,\n",
       " '부터': 283,\n",
       " '드는': 284,\n",
       " '만들어': 285,\n",
       " '이다': 286,\n",
       " '했잖아': 287,\n",
       " '따뜻하게': 288,\n",
       " '왔나': 289,\n",
       " '수': 290,\n",
       " '있으면': 291,\n",
       " '내': 292,\n",
       " '가서': 293,\n",
       " '하자고': 294,\n",
       " '다시': 295,\n",
       " '곧': 296,\n",
       " '진리': 297,\n",
       " '보세요': 298,\n",
       " '많이': 299,\n",
       " '망함': 300,\n",
       " '봅니다': 301,\n",
       " '잊고': 302,\n",
       " '여행': 303,\n",
       " '가야': 304,\n",
       " '수영장': 305,\n",
       " '같이': 306,\n",
       " '붙잡고': 307,\n",
       " '정': 308,\n",
       " '아픈가요': 309,\n",
       " '짠으로': 310,\n",
       " '업무': 311,\n",
       " '들어올': 312,\n",
       " '물어봐서': 313,\n",
       " '자꾸': 314,\n",
       " '장난': 315,\n",
       " '시간': 316,\n",
       " '개인': 317,\n",
       " '잘': 318,\n",
       " '해주세요': 319,\n",
       " '싶어': 320,\n",
       " '하고': 321,\n",
       " '하는지': 322,\n",
       " '들': 323,\n",
       " '새로': 324,\n",
       " '자도': 325,\n",
       " '감': 326,\n",
       " '이라니': 327,\n",
       " '룩': 328,\n",
       " '취미': 329,\n",
       " '다': 330,\n",
       " '쓰레기통': 331,\n",
       " '4일': 332,\n",
       " '잠깐': 333,\n",
       " '강렬한': 334,\n",
       " '해': 335,\n",
       " '모두': 336,\n",
       " '으로': 337,\n",
       " '갑작스러웠나': 338,\n",
       " '망가졌어': 339,\n",
       " '에는': 340,\n",
       " '나를': 341,\n",
       " '부족했나': 342,\n",
       " '관계': 343,\n",
       " '필요하죠': 344,\n",
       " '하면': 345,\n",
       " '했길': 346,\n",
       " '준': 347,\n",
       " '화폐': 348,\n",
       " '것': 349,\n",
       " '적': 350,\n",
       " '질질': 351,\n",
       " '켜고': 352,\n",
       " '줘': 353,\n",
       " '요': 354,\n",
       " '에요': 355,\n",
       " '패턴': 356,\n",
       " '난다': 357,\n",
       " '예요': 358,\n",
       " '데': 359,\n",
       " '막': 360,\n",
       " '목소리': 361,\n",
       " '어제': 362,\n",
       " '당신': 363,\n",
       " '두': 364,\n",
       " '인거': 365,\n",
       " '온': 366,\n",
       " '리지': 367,\n",
       " '개시': 368,\n",
       " '스트레스': 369,\n",
       " '가출': 370,\n",
       " '주는': 371,\n",
       " '하느라': 372,\n",
       " '자리': 373,\n",
       " '치킨': 374,\n",
       " '를': 375,\n",
       " '이야': 376,\n",
       " '운': 377,\n",
       " '건': 378,\n",
       " '지': 379,\n",
       " '입어': 380,\n",
       " '랑': 381,\n",
       " '돈': 382,\n",
       " '씨방': 383,\n",
       " '약': 384,\n",
       " '가족': 385,\n",
       " '애가': 386,\n",
       " '사랑': 387,\n",
       " '정말': 388,\n",
       " '거': 389,\n",
       " '한테': 390,\n",
       " '간식': 391,\n",
       " '인데': 392,\n",
       " '3': 393,\n",
       " '떨어졌어': 394,\n",
       " '수도': 395,\n",
       " '돼': 396,\n",
       " '위로': 397,\n",
       " '맞팔': 398,\n",
       " '박': 399,\n",
       " '볼까': 400,\n",
       " '더': 401,\n",
       " '싫어하지': 402,\n",
       " '서먹해졌어': 403,\n",
       " '정도': 404,\n",
       " '기운': 405,\n",
       " '오늘이': 406,\n",
       " '감히': 407,\n",
       " '게': 408,\n",
       " '죠': 409,\n",
       " '설움': 410,\n",
       " '알아차리지': 411,\n",
       " '이': 412,\n",
       " '닮아서': 413,\n",
       " '중요해요': 414,\n",
       " '확실한': 415,\n",
       " '함께': 416,\n",
       " '휴식': 417,\n",
       " '바라요': 418,\n",
       " '와': 419,\n",
       " '은': 420,\n",
       " '자신': 421,\n",
       " 'SD': 422,\n",
       " '믿어': 423,\n",
       " '가까워질': 424,\n",
       " '어서': 425,\n",
       " '있는': 426,\n",
       " '비': 427,\n",
       " '낭비': 428,\n",
       " '살까': 429,\n",
       " '중요한': 430,\n",
       " '졸려': 431,\n",
       " '득템': 432,\n",
       " '살펴': 433,\n",
       " '습관': 434,\n",
       " '아세요': 435,\n",
       " '먼저': 436,\n",
       " '감정': 437,\n",
       " '선생님': 438,\n",
       " '어떤것': 439,\n",
       " '없죠': 440,\n",
       " '나': 441,\n",
       " '되도록': 442,\n",
       " '는': 443,\n",
       " '방학': 444,\n",
       " '반': 445,\n",
       " '땀': 446,\n",
       " '가상': 447,\n",
       " '하지': 448,\n",
       " '자랑': 449,\n",
       " '돌아가서': 450,\n",
       " '이랑': 451,\n",
       " '가': 452,\n",
       " '카드': 453}"
      ]
     },
     "execution_count": 11,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "# 단어 -> 인덱스\n",
    "# 문장을 인덱스로 변환하여 모델 입력으로 사용\n",
    "word_to_index"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 12,
   "metadata": {
    "scrolled": true,
    "tags": []
   },
   "outputs": [
    {
     "data": {
      "text/plain": [
       "{0: '<PADDING>',\n",
       " 1: '<START>',\n",
       " 2: '<END>',\n",
       " 3: '<OOV>',\n",
       " 4: '쇼핑',\n",
       " 5: '서로',\n",
       " 6: '달',\n",
       " 7: '건데',\n",
       " 8: '이나',\n",
       " 9: '되',\n",
       " 10: '변화',\n",
       " 11: '즐거운',\n",
       " 12: '생각',\n",
       " 13: '콕',\n",
       " 14: '벗어나는',\n",
       " 15: '마세요',\n",
       " 16: '있어요',\n",
       " 17: '하',\n",
       " 18: '누굴',\n",
       " 19: '가지',\n",
       " 20: '사세요',\n",
       " 21: '일',\n",
       " 22: '지망',\n",
       " 23: '매일',\n",
       " 24: '갈거야',\n",
       " 25: '인게',\n",
       " 26: '심하네',\n",
       " 27: '다음',\n",
       " 28: '엉망',\n",
       " 29: '무시',\n",
       " 30: '됐으면',\n",
       " 31: '했어',\n",
       " 32: '괜찮아요',\n",
       " 33: '후회',\n",
       " 34: '풀었어',\n",
       " 35: '아님',\n",
       " 36: '남겨야',\n",
       " 37: '해보세요',\n",
       " 38: '있어',\n",
       " 39: '힘든데',\n",
       " 40: '있을까',\n",
       " 41: '식혀주세요',\n",
       " 42: '좋아요',\n",
       " 43: '옴',\n",
       " 44: '간다',\n",
       " 45: '걸린',\n",
       " 46: '듣고',\n",
       " 47: '그럴',\n",
       " 48: '1',\n",
       " 49: '없어',\n",
       " 50: '먹었는데',\n",
       " 51: '드립니다',\n",
       " 52: '보내고',\n",
       " 53: '절약',\n",
       " 54: '간장',\n",
       " 55: '말',\n",
       " 56: '개념',\n",
       " 57: '처럼',\n",
       " 58: '사이',\n",
       " 59: '키워',\n",
       " 60: '말랭이',\n",
       " 61: '같아',\n",
       " 62: '마음',\n",
       " 63: '좋은',\n",
       " 64: '그건',\n",
       " 65: '감미로운',\n",
       " 66: '감기',\n",
       " 67: '떨리니까',\n",
       " 68: '역시',\n",
       " 69: '편해요',\n",
       " 70: '알려',\n",
       " 71: '알',\n",
       " 72: '첫인상',\n",
       " 73: '그',\n",
       " 74: '싶은데',\n",
       " 75: '시켜',\n",
       " 76: '좋다',\n",
       " 77: '자의',\n",
       " 78: '개강',\n",
       " 79: '누구',\n",
       " 80: '일도',\n",
       " 81: '해봐요',\n",
       " 82: '야',\n",
       " 83: '좋겠다',\n",
       " 84: '낮잠',\n",
       " 85: '진창',\n",
       " 86: '입어볼까',\n",
       " 87: '기름',\n",
       " 88: '부터는',\n",
       " 89: '돼겠지',\n",
       " 90: '쉬는',\n",
       " 91: '추천',\n",
       " 92: '갑자기',\n",
       " 93: '살쪄도',\n",
       " 94: '출발',\n",
       " 95: '될',\n",
       " 96: '좋죠',\n",
       " 97: '나쁜',\n",
       " 98: '사는',\n",
       " 99: '왜',\n",
       " 100: '연인',\n",
       " 101: '이에요',\n",
       " 102: '상황',\n",
       " 103: '나갔어',\n",
       " 104: '말까',\n",
       " 105: '물어',\n",
       " 106: '가네요',\n",
       " 107: '가스',\n",
       " 108: '어필',\n",
       " 109: '데이터',\n",
       " 110: '불',\n",
       " 111: '책임질',\n",
       " 112: '하루',\n",
       " 113: '있어도',\n",
       " 114: '당황',\n",
       " 115: '뭘',\n",
       " 116: '중',\n",
       " 117: '니까',\n",
       " 118: 'PPL',\n",
       " 119: '보고싶었나',\n",
       " 120: '하는',\n",
       " 121: '까',\n",
       " 122: '기관',\n",
       " 123: '불편한',\n",
       " 124: '하겠어',\n",
       " 125: '하는데',\n",
       " 126: '만',\n",
       " 127: '을',\n",
       " 128: '아름다운',\n",
       " 129: 'ㅠㅠ',\n",
       " 130: '3초',\n",
       " 131: '됨',\n",
       " 132: '켜놓고',\n",
       " 133: '세수',\n",
       " 134: '싫어',\n",
       " 135: '고민',\n",
       " 136: '생활',\n",
       " 137: '좋아',\n",
       " 138: '곳',\n",
       " 139: '어디',\n",
       " 140: '가끔',\n",
       " 141: '무모한',\n",
       " 142: '좋아해주세요',\n",
       " 143: '로',\n",
       " 144: '가세',\n",
       " 145: '가려고',\n",
       " 146: '공적',\n",
       " 147: '자체',\n",
       " 148: '짧죠',\n",
       " 149: '갈',\n",
       " 150: '의',\n",
       " 151: '물어보세요',\n",
       " 152: '병원',\n",
       " 153: '놀러',\n",
       " 154: '땡',\n",
       " 155: '뭐',\n",
       " 156: '에',\n",
       " 157: '집',\n",
       " 158: '참',\n",
       " 159: '보고',\n",
       " 160: '나온거',\n",
       " 161: '부모님',\n",
       " 162: '모르고',\n",
       " 163: '비싼데',\n",
       " 164: '가고',\n",
       " 165: '있을',\n",
       " 166: '맛있게',\n",
       " 167: '오세요',\n",
       " 168: '궁금해',\n",
       " 169: '때',\n",
       " 170: '낭비하지',\n",
       " 171: '연락',\n",
       " 172: '좋더라',\n",
       " 173: '이럴',\n",
       " 174: '까지',\n",
       " 175: '싶네요',\n",
       " 176: '꼈어',\n",
       " 177: '이야기',\n",
       " 178: '같아요',\n",
       " 179: '걔',\n",
       " 180: '않을',\n",
       " 181: '걸리겠어',\n",
       " 182: '못',\n",
       " 183: '보면',\n",
       " 184: '눈물',\n",
       " 185: '먹고',\n",
       " 186: '고고',\n",
       " 187: '놓고',\n",
       " 188: '컨트롤',\n",
       " 189: '시켜야지',\n",
       " 190: '기회',\n",
       " 191: '떨리는',\n",
       " 192: '키울까',\n",
       " 193: '하세요',\n",
       " 194: '할',\n",
       " 195: '봐요',\n",
       " 196: '또',\n",
       " 197: '가장',\n",
       " 198: '간접흡연',\n",
       " 199: '찌푸려지죠',\n",
       " 200: '좋겠네요',\n",
       " 201: '눈살',\n",
       " 202: '들더라',\n",
       " 203: '최고',\n",
       " 204: '먹어야지',\n",
       " 205: '그게',\n",
       " 206: '해보여',\n",
       " 207: '개학',\n",
       " 208: '끌',\n",
       " 209: '매력',\n",
       " 210: '새',\n",
       " 211: '저',\n",
       " 212: '학교',\n",
       " 213: '된',\n",
       " 214: '가만',\n",
       " 215: '싶다',\n",
       " 216: '같',\n",
       " 217: '언제나',\n",
       " 218: '쫄딱',\n",
       " 219: '개',\n",
       " 220: '사는게',\n",
       " 221: '행복',\n",
       " 222: '빨리',\n",
       " 223: '예쁘게',\n",
       " 224: '강아지',\n",
       " 225: '드세요',\n",
       " 226: '끄고',\n",
       " 227: '소중해요',\n",
       " 228: '인',\n",
       " 229: '해도',\n",
       " 230: '단',\n",
       " 231: '제일',\n",
       " 232: '너무',\n",
       " 233: '집어서',\n",
       " 234: '서먹해',\n",
       " 235: '키우고',\n",
       " 236: '싫어요',\n",
       " 237: '그런거니',\n",
       " 238: '즐기세요',\n",
       " 239: '가보세요',\n",
       " 240: '결정',\n",
       " 241: '강원도',\n",
       " 242: '오려나',\n",
       " 243: '12시',\n",
       " 244: '가기',\n",
       " 245: '애',\n",
       " 246: '봐서',\n",
       " 247: '되겠네요',\n",
       " 248: '관리',\n",
       " 249: '버렸어',\n",
       " 250: '알아차려도',\n",
       " 251: 'SNS',\n",
       " 252: '할까',\n",
       " 253: '피',\n",
       " 254: '살찐',\n",
       " 255: '바빠서',\n",
       " 256: '보게',\n",
       " 257: '간만',\n",
       " 258: '되나',\n",
       " 259: '만나지',\n",
       " 260: '빼고',\n",
       " 261: '같은',\n",
       " 262: '키울',\n",
       " 263: '옷',\n",
       " 264: '나오세요',\n",
       " 265: '처음',\n",
       " 266: '싫다',\n",
       " 267: '안',\n",
       " 268: '내일',\n",
       " 269: '강의',\n",
       " 270: '끼리',\n",
       " 271: '먹을까',\n",
       " 272: '해볼까',\n",
       " 273: '도',\n",
       " 274: '아는데',\n",
       " 275: '갈까',\n",
       " 276: '가자고',\n",
       " 277: '나왔다',\n",
       " 278: '혼자',\n",
       " 279: '가난한',\n",
       " 280: '게임',\n",
       " 281: '친구',\n",
       " 282: '사람',\n",
       " 283: '부터',\n",
       " 284: '드는',\n",
       " 285: '만들어',\n",
       " 286: '이다',\n",
       " 287: '했잖아',\n",
       " 288: '따뜻하게',\n",
       " 289: '왔나',\n",
       " 290: '수',\n",
       " 291: '있으면',\n",
       " 292: '내',\n",
       " 293: '가서',\n",
       " 294: '하자고',\n",
       " 295: '다시',\n",
       " 296: '곧',\n",
       " 297: '진리',\n",
       " 298: '보세요',\n",
       " 299: '많이',\n",
       " 300: '망함',\n",
       " 301: '봅니다',\n",
       " 302: '잊고',\n",
       " 303: '여행',\n",
       " 304: '가야',\n",
       " 305: '수영장',\n",
       " 306: '같이',\n",
       " 307: '붙잡고',\n",
       " 308: '정',\n",
       " 309: '아픈가요',\n",
       " 310: '짠으로',\n",
       " 311: '업무',\n",
       " 312: '들어올',\n",
       " 313: '물어봐서',\n",
       " 314: '자꾸',\n",
       " 315: '장난',\n",
       " 316: '시간',\n",
       " 317: '개인',\n",
       " 318: '잘',\n",
       " 319: '해주세요',\n",
       " 320: '싶어',\n",
       " 321: '하고',\n",
       " 322: '하는지',\n",
       " 323: '들',\n",
       " 324: '새로',\n",
       " 325: '자도',\n",
       " 326: '감',\n",
       " 327: '이라니',\n",
       " 328: '룩',\n",
       " 329: '취미',\n",
       " 330: '다',\n",
       " 331: '쓰레기통',\n",
       " 332: '4일',\n",
       " 333: '잠깐',\n",
       " 334: '강렬한',\n",
       " 335: '해',\n",
       " 336: '모두',\n",
       " 337: '으로',\n",
       " 338: '갑작스러웠나',\n",
       " 339: '망가졌어',\n",
       " 340: '에는',\n",
       " 341: '나를',\n",
       " 342: '부족했나',\n",
       " 343: '관계',\n",
       " 344: '필요하죠',\n",
       " 345: '하면',\n",
       " 346: '했길',\n",
       " 347: '준',\n",
       " 348: '화폐',\n",
       " 349: '것',\n",
       " 350: '적',\n",
       " 351: '질질',\n",
       " 352: '켜고',\n",
       " 353: '줘',\n",
       " 354: '요',\n",
       " 355: '에요',\n",
       " 356: '패턴',\n",
       " 357: '난다',\n",
       " 358: '예요',\n",
       " 359: '데',\n",
       " 360: '막',\n",
       " 361: '목소리',\n",
       " 362: '어제',\n",
       " 363: '당신',\n",
       " 364: '두',\n",
       " 365: '인거',\n",
       " 366: '온',\n",
       " 367: '리지',\n",
       " 368: '개시',\n",
       " 369: '스트레스',\n",
       " 370: '가출',\n",
       " 371: '주는',\n",
       " 372: '하느라',\n",
       " 373: '자리',\n",
       " 374: '치킨',\n",
       " 375: '를',\n",
       " 376: '이야',\n",
       " 377: '운',\n",
       " 378: '건',\n",
       " 379: '지',\n",
       " 380: '입어',\n",
       " 381: '랑',\n",
       " 382: '돈',\n",
       " 383: '씨방',\n",
       " 384: '약',\n",
       " 385: '가족',\n",
       " 386: '애가',\n",
       " 387: '사랑',\n",
       " 388: '정말',\n",
       " 389: '거',\n",
       " 390: '한테',\n",
       " 391: '간식',\n",
       " 392: '인데',\n",
       " 393: '3',\n",
       " 394: '떨어졌어',\n",
       " 395: '수도',\n",
       " 396: '돼',\n",
       " 397: '위로',\n",
       " 398: '맞팔',\n",
       " 399: '박',\n",
       " 400: '볼까',\n",
       " 401: '더',\n",
       " 402: '싫어하지',\n",
       " 403: '서먹해졌어',\n",
       " 404: '정도',\n",
       " 405: '기운',\n",
       " 406: '오늘이',\n",
       " 407: '감히',\n",
       " 408: '게',\n",
       " 409: '죠',\n",
       " 410: '설움',\n",
       " 411: '알아차리지',\n",
       " 412: '이',\n",
       " 413: '닮아서',\n",
       " 414: '중요해요',\n",
       " 415: '확실한',\n",
       " 416: '함께',\n",
       " 417: '휴식',\n",
       " 418: '바라요',\n",
       " 419: '와',\n",
       " 420: '은',\n",
       " 421: '자신',\n",
       " 422: 'SD',\n",
       " 423: '믿어',\n",
       " 424: '가까워질',\n",
       " 425: '어서',\n",
       " 426: '있는',\n",
       " 427: '비',\n",
       " 428: '낭비',\n",
       " 429: '살까',\n",
       " 430: '중요한',\n",
       " 431: '졸려',\n",
       " 432: '득템',\n",
       " 433: '살펴',\n",
       " 434: '습관',\n",
       " 435: '아세요',\n",
       " 436: '먼저',\n",
       " 437: '감정',\n",
       " 438: '선생님',\n",
       " 439: '어떤것',\n",
       " 440: '없죠',\n",
       " 441: '나',\n",
       " 442: '되도록',\n",
       " 443: '는',\n",
       " 444: '방학',\n",
       " 445: '반',\n",
       " 446: '땀',\n",
       " 447: '가상',\n",
       " 448: '하지',\n",
       " 449: '자랑',\n",
       " 450: '돌아가서',\n",
       " 451: '이랑',\n",
       " 452: '가',\n",
       " 453: '카드'}"
      ]
     },
     "execution_count": 12,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "# 인덱스 -> 단어\n",
    "# 모델의 예측 결과인 인덱스를 문장으로 변환시 사용\n",
    "index_to_word\n"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "<br>\n",
    "<br>\n",
    "\n",
    "# 전처리"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 13,
   "metadata": {},
   "outputs": [],
   "source": [
    "# 문장을 인덱스로 변환\n",
    "def convert_text_to_index(sentences, vocabulary, type): \n",
    "    \n",
    "    sentences_index = []\n",
    "    \n",
    "    # 모든 문장에 대해서 반복\n",
    "    for sentence in sentences:\n",
    "        sentence_index = []\n",
    "        \n",
    "        # 디코더 입력일 경우 맨 앞에 START 태그 추가\n",
    "        if type == DECODER_INPUT:\n",
    "            sentence_index.extend([vocabulary[STA]])\n",
    "        \n",
    "        # 문장의 단어들을 띄어쓰기로 분리\n",
    "        for word in sentence.split():\n",
    "            if vocabulary.get(word) is not None:\n",
    "                # 사전에 있는 단어면 해당 인덱스를 추가\n",
    "                sentence_index.extend([vocabulary[word]])\n",
    "            else:\n",
    "                # 사전에 없는 단어면 OOV 인덱스를 추가\n",
    "                sentence_index.extend([vocabulary[OOV]])\n",
    "\n",
    "        # 최대 길이 검사\n",
    "        if type == DECODER_TARGET:\n",
    "            # 디코더 목표일 경우 맨 뒤에 END 태그 추가\n",
    "            if len(sentence_index) >= max_sequences:\n",
    "                sentence_index = sentence_index[:max_sequences-1] + [vocabulary[END]]\n",
    "            else:\n",
    "                sentence_index += [vocabulary[END]]\n",
    "        else:\n",
    "            if len(sentence_index) > max_sequences:\n",
    "                sentence_index = sentence_index[:max_sequences]\n",
    "            \n",
    "        # 최대 길이에 없는 공간은 패딩 인덱스로 채움\n",
    "        sentence_index += (max_sequences - len(sentence_index)) * [vocabulary[PAD]]\n",
    "        \n",
    "        # 문장의 인덱스 배열을 추가\n",
    "        sentences_index.append(sentence_index)\n",
    "\n",
    "    return np.asarray(sentences_index)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "Seq2Seq에서는 학습시 다음과 같이 총 3개의 데이터가 필요합니다.\n",
    "\n",
    "인코더 입력 : 12시 땡<br>\n",
    "디코더 입력 : START 하루 가 또 가네요<br>\n",
    "디코더 출력 : 하루 가 또 가네요 END\n",
    "<br>\n",
    "원래 Seq2Seq는 디코더의 현재 출력이 디코더의 다음 입력으로 들어갑니다.<br>\n",
    "다만 학습에서는 굳이 이렇게 하지 않고 디코더 입력과 디코더 출력의 데이터를 각각 만듭니다. <br>\n",
    "<br>\n",
    "그러나 예측시에는 이런 방식이 불가능합니다.<br>\n",
    "출력값을 미리 알지 못하기 때문에, 디코더 입력을 사전에 생성할 수가 없습니다.<br>\n",
    "이런 문제를 해결하기 위해 훈련 모델과 예측 모델을 따로 구성해야 합니다.<br>\n",
    "모델 생성 부분에서 다시 자세히 설명을 드리겠습니다.<br>\n",
    "<br>\n",
    "<br>"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": []
  },
  {
   "cell_type": "code",
   "execution_count": 14,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "첫번째 question: 12시 땡\n",
      "첫번째 Encoder 입력: [243 154   0   0   0   0   0   0   0   0   0   0   0   0   0   0   0   0\n",
      "   0   0   0   0   0   0   0   0   0   0   0   0]\n",
      "\n",
      "index_to_word[ 125 ]: 하는데\n",
      "index_to_word[ 308 ]: 정\n"
     ]
    }
   ],
   "source": [
    "# 인코더 입력 인덱스 변환\n",
    "x_encoder = convert_text_to_index(question, word_to_index, ENCODER_INPUT)\n",
    "\n",
    "print('첫번째 question:', question[0])\n",
    "# 첫 번째 인코더 입력 출력 (12시 땡)\n",
    "print('첫번째 Encoder 입력:',x_encoder[0])\n",
    "print()\n",
    "\n",
    "# 출력된 125, 308은 word의 index\n",
    "print('index_to_word[ 125 ]:', index_to_word[ 125 ])\n",
    "print('index_to_word[ 308 ]:', index_to_word[ 308 ])"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 15,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "첫번째 answer: 하루 가 또 가네요\n",
      "첫번째 Decoder input: [  1 112 452 196 106   0   0   0   0   0   0   0   0   0   0   0   0   0\n",
      "   0   0   0   0   0   0   0   0   0   0   0   0]\n",
      "\n",
      "index_to_word[   1 ]: <START>\n",
      "index_to_word[ 259 ]: 만나지\n",
      "index_to_word[ 223 ]: 예쁘게\n",
      "index_to_word[ 114 ]: 당황\n",
      "index_to_word[  74 ]: 싶은데\n"
     ]
    }
   ],
   "source": [
    "# 디코더 입력 인덱스 변환\n",
    "x_decoder = convert_text_to_index(answer, word_to_index, DECODER_INPUT)\n",
    "\n",
    "print('첫번째 answer:', answer[0])\n",
    "print('첫번째 Decoder input:', x_decoder[0])\n",
    "print()\n",
    "\n",
    "# 출력된 1, 259, 223, 114, 74는 word의 index\n",
    "print('index_to_word[   1 ]:', index_to_word[   1 ])\n",
    "print('index_to_word[ 259 ]:', index_to_word[ 259 ])\n",
    "print('index_to_word[ 223 ]:', index_to_word[ 223 ])\n",
    "print('index_to_word[ 114 ]:', index_to_word[ 114 ])\n",
    "print('index_to_word[  74 ]:', index_to_word[  74 ])"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 16,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "첫번째 answer: 하루 가 또 가네요\n",
      "첫번쨰 Decoder onput: [112 452 196 106   2   0   0   0   0   0   0   0   0   0   0   0   0   0\n",
      "   0   0   0   0   0   0   0   0   0   0   0   0]\n",
      "\n",
      "index_to_word[ 259 ]: 만나지\n",
      "index_to_word[ 223 ]: 예쁘게\n",
      "index_to_word[ 114 ]: 당황\n",
      "index_to_word[  74 ]: 싶은데\n",
      "index_to_word[   2 ]: <END>\n"
     ]
    }
   ],
   "source": [
    "# 디코더 목표 인덱스 변환\n",
    "y_decoder = convert_text_to_index(answer, word_to_index, DECODER_TARGET)\n",
    "\n",
    "# 첫 번째 디코더 목표 출력 (하루 가 또 가네요 END)\n",
    "y_decoder[0]\n",
    "\n",
    "print('첫번째 answer:', answer[0])\n",
    "print('첫번쨰 Decoder onput:', y_decoder[0])\n",
    "print()\n",
    "\n",
    "# 출력된 1, 259, 223, 114, 74는 word의 index\n",
    "print('index_to_word[ 259 ]:', index_to_word[ 259 ])\n",
    "print('index_to_word[ 223 ]:', index_to_word[ 223 ])\n",
    "print('index_to_word[ 114 ]:', index_to_word[ 114 ])\n",
    "print('index_to_word[  74 ]:', index_to_word[  74 ])\n",
    "print('index_to_word[   2 ]:', index_to_word[   2 ])"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 17,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "array([[0., 0., 0., ..., 0., 0., 0.],\n",
       "       [0., 0., 0., ..., 0., 0., 0.],\n",
       "       [0., 0., 0., ..., 0., 0., 0.],\n",
       "       ...,\n",
       "       [0., 0., 0., ..., 0., 0., 0.],\n",
       "       [0., 0., 0., ..., 0., 0., 0.],\n",
       "       [0., 0., 0., ..., 0., 0., 0.]])"
      ]
     },
     "execution_count": 17,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "# 원핫인코딩 초기화\n",
    "one_hot_data = np.zeros((len(y_decoder), max_sequences, len(words)))\n",
    "one_hot_data[0]"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 18,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "array([112, 452, 196, 106,   2,   0,   0,   0,   0,   0,   0,   0,   0,\n",
       "         0,   0,   0,   0,   0,   0,   0,   0,   0,   0,   0,   0,   0,\n",
       "         0,   0,   0,   0])"
      ]
     },
     "execution_count": 18,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "#one_hot_data의 첫 row에 259번째 column에 '하루'\n",
    "#one_hot_data의 첫 row에 223번째 column에 '가'\n",
    "#one_hot_data의 첫 row에 114번째 column에 '또'.... 를 1로 변경\n",
    "y_decoder[0]"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 19,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "array([[0., 0., 0., ..., 0., 0., 0.],\n",
       "       [0., 0., 0., ..., 0., 1., 0.],\n",
       "       [0., 0., 0., ..., 0., 0., 0.],\n",
       "       ...,\n",
       "       [1., 0., 0., ..., 0., 0., 0.],\n",
       "       [1., 0., 0., ..., 0., 0., 0.],\n",
       "       [1., 0., 0., ..., 0., 0., 0.]])"
      ]
     },
     "execution_count": 19,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "# 디코더 목표를 원핫인코딩으로 변환\n",
    "# 학습시 입력은 인덱스이지만, 출력은 원핫인코딩 형식임\n",
    "for i, sequence in enumerate(y_decoder):\n",
    "    for j, index in enumerate(sequence):\n",
    "        one_hot_data[i, j, index] = 1\n",
    "\n",
    "# 디코더 목표 설정\n",
    "y_decoder = one_hot_data\n",
    "\n",
    "# 첫 번째 디코더 목표 출력\n",
    "y_decoder[0]"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 32,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "1.0"
      ]
     },
     "execution_count": 32,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "# 259번째 index (하루) 가 1임\n",
    "y_decoder[0][0][112]"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "인코더 입력과 디코더 입력은 임베딩 레이어에 들어가는 인덱스 배열입니다.<br>\n",
    "반면에 디코더 출력은 원핫인코딩 형식이 되어야 합니다.<br>\n",
    "디코더의 마지막 Dense 레이어에서 softmax로 나오기 때문입니다.<br>"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "<br>\n",
    "<br>\n",
    "\n",
    "# 모델 생성"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 21,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "WARNING:tensorflow:Layer lstm will not use cuDNN kernel since it doesn't meet the cuDNN kernel criteria. It will use generic GPU kernel as fallback when running on GPU\n"
     ]
    }
   ],
   "source": [
    "#--------------------------------------------\n",
    "# 훈련 모델 인코더 정의\n",
    "#--------------------------------------------\n",
    "\n",
    "# 입력 문장의 인덱스 시퀀스를 입력으로 받음\n",
    "encoder_inputs = layers.Input(shape=(None,))\n",
    "\n",
    "# 임베딩 레이어\n",
    "encoder_outputs = layers.Embedding(len(words), embedding_dim)(encoder_inputs)\n",
    "\n",
    "# return_state가 True면 상태값 리턴\n",
    "# LSTM은 state_h(hidden state)와 state_c(cell state) 2개의 상태 존재\n",
    "encoder_outputs, state_h, state_c = layers.LSTM(lstm_hidden_dim,\n",
    "                                                dropout=0.1,\n",
    "                                                recurrent_dropout=0.5,\n",
    "                                                return_state=True)(encoder_outputs)\n",
    "\n",
    "# 히든 상태와 셀 상태를 하나로 묶음\n",
    "# Decoder의 initial state에 넣어주기 위함\n",
    "# 즉, input sentence의 모든 정보를 통해 Decoding 하기 위함\n",
    "encoder_states = [state_h, state_c]\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 31,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "<KerasTensor: shape=(None, 128) dtype=float32 (created by layer 'lstm')>"
      ]
     },
     "execution_count": 31,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "encoder_outputs"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 22,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "[<KerasTensor: shape=(None, 128) dtype=float32 (created by layer 'lstm')>,\n",
       " <KerasTensor: shape=(None, 128) dtype=float32 (created by layer 'lstm')>]"
      ]
     },
     "execution_count": 22,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "encoder_states"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 23,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "WARNING:tensorflow:Layer lstm_1 will not use cuDNN kernel since it doesn't meet the cuDNN kernel criteria. It will use generic GPU kernel as fallback when running on GPU\n"
     ]
    }
   ],
   "source": [
    "#--------------------------------------------\n",
    "# 훈련 모델 디코더 정의\n",
    "#--------------------------------------------\n",
    "\n",
    "# 목표 문장의 인덱스 시퀀스를 입력으로 받음\n",
    "decoder_inputs = layers.Input(shape=(None,))\n",
    "\n",
    "# 임베딩 레이어\n",
    "decoder_embedding = layers.Embedding(len(words), embedding_dim)\n",
    "decoder_outputs = decoder_embedding(decoder_inputs)\n",
    "\n",
    "# 인코더와 달리 return_sequences를 True로 설정하여 모든 타임 스텝 출력값 리턴\n",
    "# 모든 타임 스텝의 출력값들을 다음 레이어의 Dense()로 처리하기 위함\n",
    "decoder_lstm = layers.LSTM(lstm_hidden_dim,\n",
    "                           dropout=0.1,\n",
    "                           recurrent_dropout=0.5,\n",
    "                           return_state=True,\n",
    "                           return_sequences=True)\n",
    "\n",
    "# initial_state를 인코더의 상태로 초기화\n",
    "decoder_outputs, _, _ = decoder_lstm(decoder_outputs,\n",
    "                                     initial_state=encoder_states)\n",
    "\n",
    "# 단어의 개수만큼 노드의 개수를 설정하여 원핫 형식으로 각 단어 인덱스를 출력\n",
    "decoder_dense = layers.Dense(len(words), activation='softmax')\n",
    "decoder_outputs = decoder_dense(decoder_outputs)\n"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "지금까지의 예제는 Sequential 방식의 모델이었습니다.<br>\n",
    "하지만 이번에는 함수형 API 모델을 사용했습니다.<br>\n",
    "인코더와 디코더가 따로 분리되어야 하는데, 단순히 레이어를 추가하여 붙이는 순차형으로는 구현이 불가능하기 때문입니다. <br>\n",
    "<br>\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 24,
   "metadata": {},
   "outputs": [],
   "source": [
    "#--------------------------------------------\n",
    "# 훈련 모델 정의\n",
    "#--------------------------------------------\n",
    "\n",
    "# 입력과 출력으로 함수형 API 모델 생성\n",
    "model = models.Model([encoder_inputs, decoder_inputs], decoder_outputs)\n",
    "\n",
    "# 학습 방법 설정\n",
    "model.compile(optimizer='rmsprop',\n",
    "              loss='categorical_crossentropy',\n",
    "              metrics=['acc'])    "
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "Model() 함수로 입력과 출력을 따로 설정하여 모델을 만듭니다.<br>\n",
    "그다음 compile과 fit은 이전과 동일하게 적용하시면 됩니다.<br>\n",
    "<br>\n",
    "<br>"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 25,
   "metadata": {},
   "outputs": [],
   "source": [
    "#--------------------------------------------\n",
    "#  예측 모델 인코더 정의\n",
    "#--------------------------------------------\n",
    "\n",
    "# 훈련 모델의 인코더 상태를 사용하여 예측 모델 인코더 설정\n",
    "encoder_model = models.Model(encoder_inputs, encoder_states)\n",
    "\n",
    "#--------------------------------------------\n",
    "# 예측 모델 디코더 정의\n",
    "#--------------------------------------------\n",
    "\n",
    "# 예측시에는 훈련시와 달리 타임 스텝을 한 단계씩 수행\n",
    "# 매번 이전 디코더 상태를 입력으로 받아서 새로 설정\n",
    "decoder_state_input_h = layers.Input(shape=(lstm_hidden_dim,))\n",
    "decoder_state_input_c = layers.Input(shape=(lstm_hidden_dim,))\n",
    "decoder_states_inputs = [decoder_state_input_h, decoder_state_input_c]    \n",
    "\n",
    "# 임베딩 레이어\n",
    "decoder_outputs = decoder_embedding(decoder_inputs)\n",
    "\n",
    "# LSTM 레이어\n",
    "decoder_outputs, state_h, state_c = decoder_lstm(decoder_outputs,\n",
    "                                                 initial_state=decoder_states_inputs)\n",
    "\n",
    "# 히든 상태와 셀 상태를 하나로 묶음\n",
    "decoder_states = [state_h, state_c]\n",
    "\n",
    "# Dense 레이어를 통해 원핫 형식으로 각 단어 인덱스를 출력\n",
    "decoder_outputs = decoder_dense(decoder_outputs)\n",
    "\n",
    "# 예측 모델 디코더 설정\n",
    "decoder_model = models.Model([decoder_inputs] + decoder_states_inputs,\n",
    "                      [decoder_outputs] + decoder_states)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "예측 모델은 이미 학습된 훈련 모델의 레이어들을 그대로 재사용합니다. 예측 모델 인코더는 훈련 모델 인코더과 동일합니다. 그러나 예측 모델 디코더는 매번 LSTM 상태값을 입력으로 받습니다. 또한 디코더의 LSTM 상태를 출력값과 같이 내보내서, 다음 번 입력에 넣습니다. \n",
    "\n",
    "이렇게 하는 이유는 LSTM을 딱 한번의 타임 스텝만 실행하기 때문입니다. 그래서 매번 상태값을 새로 초기화 해야 합니다. 이와 반대로 훈련할때는 문장 전체를 계속 LSTM으로 돌리기 때문에 자동으로 상태값이 전달됩니다. "
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 26,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Model: \"model\"\n",
      "__________________________________________________________________________________________________\n",
      "Layer (type)                    Output Shape         Param #     Connected to                     \n",
      "==================================================================================================\n",
      "input_1 (InputLayer)            [(None, None)]       0                                            \n",
      "__________________________________________________________________________________________________\n",
      "input_2 (InputLayer)            [(None, None)]       0                                            \n",
      "__________________________________________________________________________________________________\n",
      "embedding (Embedding)           (None, None, 100)    45400       input_1[0][0]                    \n",
      "__________________________________________________________________________________________________\n",
      "embedding_1 (Embedding)         (None, None, 100)    45400       input_2[0][0]                    \n",
      "__________________________________________________________________________________________________\n",
      "lstm (LSTM)                     [(None, 128), (None, 117248      embedding[0][0]                  \n",
      "__________________________________________________________________________________________________\n",
      "lstm_1 (LSTM)                   [(None, None, 128),  117248      embedding_1[0][0]                \n",
      "                                                                 lstm[0][1]                       \n",
      "                                                                 lstm[0][2]                       \n",
      "__________________________________________________________________________________________________\n",
      "dense (Dense)                   (None, None, 454)    58566       lstm_1[0][0]                     \n",
      "==================================================================================================\n",
      "Total params: 383,862\n",
      "Trainable params: 383,862\n",
      "Non-trainable params: 0\n",
      "__________________________________________________________________________________________________\n"
     ]
    }
   ],
   "source": [
    "model.summary()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 27,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Model: \"model_1\"\n",
      "_________________________________________________________________\n",
      "Layer (type)                 Output Shape              Param #   \n",
      "=================================================================\n",
      "input_1 (InputLayer)         [(None, None)]            0         \n",
      "_________________________________________________________________\n",
      "embedding (Embedding)        (None, None, 100)         45400     \n",
      "_________________________________________________________________\n",
      "lstm (LSTM)                  [(None, 128), (None, 128) 117248    \n",
      "=================================================================\n",
      "Total params: 162,648\n",
      "Trainable params: 162,648\n",
      "Non-trainable params: 0\n",
      "_________________________________________________________________\n"
     ]
    }
   ],
   "source": [
    "encoder_model.summary()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 28,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Model: \"model_2\"\n",
      "__________________________________________________________________________________________________\n",
      "Layer (type)                    Output Shape         Param #     Connected to                     \n",
      "==================================================================================================\n",
      "input_2 (InputLayer)            [(None, None)]       0                                            \n",
      "__________________________________________________________________________________________________\n",
      "embedding_1 (Embedding)         (None, None, 100)    45400       input_2[0][0]                    \n",
      "__________________________________________________________________________________________________\n",
      "input_3 (InputLayer)            [(None, 128)]        0                                            \n",
      "__________________________________________________________________________________________________\n",
      "input_4 (InputLayer)            [(None, 128)]        0                                            \n",
      "__________________________________________________________________________________________________\n",
      "lstm_1 (LSTM)                   [(None, None, 128),  117248      embedding_1[1][0]                \n",
      "                                                                 input_3[0][0]                    \n",
      "                                                                 input_4[0][0]                    \n",
      "__________________________________________________________________________________________________\n",
      "dense (Dense)                   (None, None, 454)    58566       lstm_1[1][0]                     \n",
      "==================================================================================================\n",
      "Total params: 221,214\n",
      "Trainable params: 221,214\n",
      "Non-trainable params: 0\n",
      "__________________________________________________________________________________________________\n"
     ]
    }
   ],
   "source": [
    "# Decoder_model에는 \n",
    "decoder_model.summary()"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "<br>\n",
    "<br>\n",
    "\n",
    "# 훈련 및 테스트"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 29,
   "metadata": {},
   "outputs": [],
   "source": [
    "# 인덱스를 문장으로 변환\n",
    "def convert_index_to_text(indexs, vocabulary): \n",
    "    \n",
    "    sentence = ''\n",
    "    \n",
    "    # 모든 문장에 대해서 반복\n",
    "    for index in indexs:\n",
    "        if index == END_INDEX:\n",
    "            # 종료 인덱스면 중지\n",
    "            break;\n",
    "        elif vocabulary.get(index) is not None:\n",
    "            # 사전에 있는 인덱스면 해당 단어를 추가\n",
    "            sentence += vocabulary[index]\n",
    "        else:\n",
    "            # 사전에 없는 인덱스면 OOV 단어를 추가\n",
    "            sentence += vocabulary[OOV_INDEX]\n",
    "            \n",
    "        # 빈칸 추가\n",
    "        sentence += ' '\n",
    "\n",
    "    return sentence"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 30,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Total Epoch : 1\n",
      "accuracy : 0.8396666646003723\n",
      "loss : 0.6992223262786865\n",
      "저 도 이 요 \n",
      "\n",
      "Total Epoch : 2\n",
      "accuracy : 0.925000011920929\n",
      "loss : 0.34692755341529846\n",
      "저 은 에는 좋죠 \n",
      "\n",
      "Total Epoch : 3\n",
      "accuracy : 0.9683333039283752\n",
      "loss : 0.14421546459197998\n",
      "저 은 언제나 좋죠 \n",
      "\n",
      "Total Epoch : 4\n",
      "accuracy : 0.9746666550636292\n",
      "loss : 0.08817499876022339\n",
      "저 은 언제나 좋죠 \n",
      "\n",
      "Total Epoch : 5\n",
      "accuracy : 0.9769999980926514\n",
      "loss : 0.06913413852453232\n",
      "여행 은 언제나 좋죠 \n",
      "\n",
      "Total Epoch : 6\n",
      "accuracy : 0.9823333621025085\n",
      "loss : 0.04941220581531525\n",
      "여행 은 언제나 좋죠 \n",
      "\n",
      "Total Epoch : 7\n",
      "accuracy : 0.9893333315849304\n",
      "loss : 0.03170783445239067\n",
      "여행 은 언제나 좋죠 \n",
      "\n",
      "Total Epoch : 8\n",
      "accuracy : 0.9929999709129333\n",
      "loss : 0.02188185416162014\n",
      "여행 은 언제나 좋죠 \n",
      "\n",
      "Total Epoch : 9\n",
      "accuracy : 0.9976666569709778\n",
      "loss : 0.01334693469107151\n",
      "여행 은 언제나 좋죠 \n",
      "\n",
      "Total Epoch : 10\n",
      "accuracy : 0.9983333349227905\n",
      "loss : 0.006254453677684069\n",
      "여행 은 언제나 좋죠 \n",
      "\n",
      "Total Epoch : 11\n",
      "accuracy : 0.9993333220481873\n",
      "loss : 0.0033200467005372047\n",
      "여행 은 언제나 좋죠 \n",
      "\n",
      "Total Epoch : 12\n",
      "accuracy : 0.9993333220481873\n",
      "loss : 0.004725079517811537\n",
      "여행 은 언제나 좋죠 \n",
      "\n",
      "Total Epoch : 13\n",
      "accuracy : 1.0\n",
      "loss : 0.0003490669187158346\n",
      "여행 은 언제나 좋죠 \n",
      "\n",
      "Total Epoch : 14\n",
      "accuracy : 1.0\n",
      "loss : 0.00018462151638232172\n",
      "여행 은 언제나 좋죠 \n",
      "\n",
      "Total Epoch : 15\n",
      "accuracy : 0.9986666440963745\n",
      "loss : 0.0030060848221182823\n",
      "여행 은 언제나 좋죠 \n",
      "\n",
      "Total Epoch : 16\n",
      "accuracy : 1.0\n",
      "loss : 5.5225667892955244e-05\n",
      "여행 은 언제나 좋죠 \n",
      "\n",
      "Total Epoch : 17\n",
      "accuracy : 0.999666690826416\n",
      "loss : 0.0008619733271189034\n",
      "여행 은 언제나 좋죠 \n",
      "\n",
      "Total Epoch : 18\n",
      "accuracy : 1.0\n",
      "loss : 2.4972070605144836e-05\n",
      "여행 은 언제나 좋죠 \n",
      "\n",
      "Total Epoch : 19\n",
      "accuracy : 1.0\n",
      "loss : 7.29823368601501e-05\n",
      "여행 은 언제나 좋죠 \n",
      "\n",
      "Total Epoch : 20\n",
      "accuracy : 1.0\n",
      "loss : 2.374743780819699e-05\n",
      "여행 은 언제나 좋죠 \n",
      "\n"
     ]
    }
   ],
   "source": [
    "# 에폭 반복\n",
    "for epoch in range(20):\n",
    "    print('Total Epoch :', epoch + 1)\n",
    "\n",
    "    # 훈련 시작\n",
    "    history = model.fit([x_encoder, x_decoder],\n",
    "                        y_decoder,\n",
    "                        epochs=100,\n",
    "                        batch_size=64,\n",
    "                        verbose=0)\n",
    "    \n",
    "    # 정확도와 손실 출력\n",
    "    print('accuracy :', history.history['acc'][-1])\n",
    "    print('loss :', history.history['loss'][-1])\n",
    "    \n",
    "    # 문장 예측 테스트\n",
    "    # (3 박 4일 놀러 가고 싶다) -> (여행 은 언제나 좋죠)\n",
    "    input_encoder = x_encoder[2].reshape(1, x_encoder[2].shape[0])\n",
    "    input_decoder = x_decoder[2].reshape(1, x_decoder[2].shape[0])\n",
    "    results = model.predict([input_encoder, input_decoder])\n",
    "    \n",
    "    # 결과의 원핫인코딩 형식을 인덱스로 변환\n",
    "    # 1축을 기준으로 가장 높은 값의 위치를 구함\n",
    "    indexs = np.argmax(results[0], 1) \n",
    "    \n",
    "    # 인덱스를 문장으로 변환\n",
    "    sentence = convert_index_to_text(indexs, index_to_word)\n",
    "    print(sentence)\n",
    "    print()\n"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "학습이 진행될수록 예측 문장이 제대로 생성되는 것을 볼 수 있습니다. 다만 여기서의 예측은 단순히 테스트를 위한 것이라, 인코더 입력과 디코더 입력 데이터가 동시에 사용됩니다. 아래 문장 생성에서는 예측 모델을 적용하기 때문에, 오직 인코더 입력 데이터만 집어 넣습니다.\n",
    "<br>\n",
    "<br>\n",
    "<br>"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 33,
   "metadata": {},
   "outputs": [],
   "source": [
    "# 모델 저장\n",
    "encoder_model.save('./model/seq2seq_chatbot_encoder_model.h5')\n",
    "decoder_model.save('./model/seq2seq_chatbot_decoder_model.h5')\n",
    "\n",
    "# 인덱스 저장\n",
    "with open('./model/word_to_index.pkl', 'wb') as f:\n",
    "    pickle.dump(word_to_index, f, pickle.HIGHEST_PROTOCOL)\n",
    "with open('./model/index_to_word.pkl', 'wb') as f:\n",
    "    pickle.dump(index_to_word, f, pickle.HIGHEST_PROTOCOL)    "
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "<br>\n",
    "<br>\n",
    "\n",
    "# 문장 생성"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 34,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "WARNING:tensorflow:Layer lstm will not use cuDNN kernel since it doesn't meet the cuDNN kernel criteria. It will use generic GPU kernel as fallback when running on GPU\n",
      "WARNING:tensorflow:No training configuration found in the save file, so the model was *not* compiled. Compile it manually.\n",
      "WARNING:tensorflow:Layer lstm_1 will not use cuDNN kernel since it doesn't meet the cuDNN kernel criteria. It will use generic GPU kernel as fallback when running on GPU\n",
      "WARNING:tensorflow:No training configuration found in the save file, so the model was *not* compiled. Compile it manually.\n"
     ]
    }
   ],
   "source": [
    "# 모델 파일 로드\n",
    "encoder_model = models.load_model('./model/seq2seq_chatbot_encoder_model.h5')\n",
    "decoder_model = models.load_model('./model/seq2seq_chatbot_decoder_model.h5')\n",
    "\n",
    "# 인덱스 파일 로드\n",
    "with open('./model/word_to_index.pkl', 'rb') as f:\n",
    "    word_to_index = pickle.load(f)\n",
    "with open('./model/index_to_word.pkl', 'rb') as f:\n",
    "    index_to_word = pickle.load(f)    "
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 35,
   "metadata": {},
   "outputs": [],
   "source": [
    "# 예측을 위한 입력 생성\n",
    "def make_predict_input(sentence):\n",
    "\n",
    "    sentences = []\n",
    "    sentences.append(sentence)\n",
    "    sentences = pos_tag(sentences)\n",
    "    input_seq = convert_text_to_index(sentences, word_to_index, ENCODER_INPUT)\n",
    "    \n",
    "    return input_seq"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 36,
   "metadata": {},
   "outputs": [],
   "source": [
    "# 텍스트 생성\n",
    "def generate_text(input_seq):\n",
    "    \n",
    "    # 입력을 인코더에 넣어 마지막 상태 구함\n",
    "    states = encoder_model.predict(input_seq)\n",
    "\n",
    "    # 목표 시퀀스 초기화\n",
    "    target_seq = np.zeros((1, 1))\n",
    "    \n",
    "    # 목표 시퀀스의 첫 번째에 <START> 태그 추가\n",
    "    target_seq[0, 0] = STA_INDEX\n",
    "    \n",
    "    # 인덱스 초기화\n",
    "    indexs = []\n",
    "    \n",
    "    # 디코더 타임 스텝 반복\n",
    "    while 1:\n",
    "        # 디코더로 현재 타임 스텝 출력 구함\n",
    "        # 처음에는 인코더 상태를, 다음부터 이전 디코더 상태로 초기화\n",
    "        decoder_outputs, state_h, state_c = decoder_model.predict(\n",
    "                                                [target_seq] + states)\n",
    "\n",
    "        # 결과의 원핫인코딩 형식을 인덱스로 변환\n",
    "        index = np.argmax(decoder_outputs[0, 0, :])\n",
    "        indexs.append(index)\n",
    "        \n",
    "        # 종료 검사\n",
    "        if index == END_INDEX or len(indexs) >= max_sequences:\n",
    "            break\n",
    "\n",
    "        # 목표 시퀀스를 바로 이전의 출력으로 설정\n",
    "        target_seq = np.zeros((1, 1))\n",
    "        target_seq[0, 0] = index\n",
    "        \n",
    "        # 디코더의 이전 상태를 다음 디코더 예측에 사용\n",
    "        states = [state_h, state_c]\n",
    "\n",
    "    # 인덱스를 문장으로 변환\n",
    "    sentence = convert_index_to_text(indexs, index_to_word)\n",
    "        \n",
    "    return sentence"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "제일 첫 단어는 START로 시작합니다. 그리고 출력으로 나온 인덱스를 디코더 입력으로 넣고 다시 예측을 반복합니다. 상태값을 받아 다시 입력으로 같이 넣는 것에 주의하시기 바랍니다. END 태그가 나오면 문장 생성을 종료합니다.\n",
    "<br>\n",
    "<br>\n",
    "<br>"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 42,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "array([[  3, 412,  42,   0,   0,   0,   0,   0,   0,   0,   0,   0,   0,\n",
       "          0,   0,   0,   0,   0,   0,   0,   0,   0,   0,   0,   0,   0,\n",
       "          0,   0,   0,   0]])"
      ]
     },
     "execution_count": 42,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "# 문장을 인덱스로 변환\n",
    "input_seq = make_predict_input('휴강이 좋아요')\n",
    "input_seq\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 43,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "'병원 가세 요 '"
      ]
     },
     "execution_count": 43,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "# 예측 모델로 텍스트 생성\n",
    "sentence = generate_text(input_seq)\n",
    "sentence\n"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "데이터셋에 있는 문장과 똑같은 입력을 넣으니, 역시 정확히 일치하는 답변이 출력되었습니다.\n",
    "<br>\n",
    "<br>\n",
    "<br>"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 44,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "array([[109, 269, 232,  42,   0,   0,   0,   0,   0,   0,   0,   0,   0,\n",
       "          0,   0,   0,   0,   0,   0,   0,   0,   0,   0,   0,   0,   0,\n",
       "          0,   0,   0,   0]])"
      ]
     },
     "execution_count": 44,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "# 문장을 인덱스로 변환\n",
    "input_seq = make_predict_input('데이터 강의 너무 좋아요')\n",
    "input_seq\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 45,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "'최고 의 강의 에요 '"
      ]
     },
     "execution_count": 45,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "# 예측 모델로 텍스트 생성\n",
    "sentence = generate_text(input_seq)\n",
    "sentence\n"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "최고의 강의입니다\n",
    "<br>\n",
    "<br>\n",
    "<br>"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 51,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "array([[  3, 399,   3,   3, 143,   3,   0,   0,   0,   0,   0,   0,   0,\n",
       "          0,   0,   0,   0,   0,   0,   0,   0,   0,   0,   0,   0,   0,\n",
       "          0,   0,   0,   0]])"
      ]
     },
     "execution_count": 51,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "# 문장을 인덱스로 변환\n",
    "input_seq = make_predict_input('4박5일 욜로가려고요')\n",
    "input_seq"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 52,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "'가세 요 '"
      ]
     },
     "execution_count": 52,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "# 예측 모델로 텍스트 생성\n",
    "sentence = generate_text(input_seq)\n",
    "sentence"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "하지만 데이터셋에 없던 '4박5일, 욜로'로 입력을 수정하니, 전혀 다른 문장이 출력되었습니다.<br>\n",
    "이는 우리가 데이터의 일부인 100개 문장만 학습했기 때문입니다.<br>\n",
    "데이터의 개수를 늘려서 훈련할수록 일반화 능력이 더욱 높아집니다."
   ]
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "Python 3 (ipykernel)",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.9.7"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 4
}
